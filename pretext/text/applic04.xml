<?xml version="1.0" encoding="UTF-8" ?>
<!-- Copyright 2018 Joel Feldman, Andrew Rechnitzer and Elyse Yeager -->
<!-- This work is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License-->
<!-- https://creativecommons.org/licenses/by-nc-sa/4.0 -->
<section xml:id="sec_DIFFTaylor" xmlns:xi="http://www.w3.org/2001/XInclude">
<title>Approximating Functions Near a Specified Point <mdash/> Taylor Polynomials</title>
<shorttitle>Taylor Polynomials</shorttitle>
<introduction>

<p>Suppose that you are interested in the values of some function <m>f(x)</m> for
<m>x</m> near some fixed point <m>a</m>. When the function is a polynomial or a rational
function we can use some arithmetic (and maybe some hard work) to write down
the answer. For example:
<md>
<mrow>
  f(x) &amp;= \frac{x^2-3}{x^2-2x+4}
</mrow><mrow>
  f(1/5) &amp;= \frac{ \frac{1}{25}-3}{\frac{1}{25}-\frac{2}{5}+4 }
  = \frac{\frac{1-75}{25} }{\frac{1-10+100}{25}}
</mrow><mrow>
  &amp;= \frac{-74}{91}
</mrow>
</md>
Tedious, but we can do it. On the other hand if you are asked to compute
<m>\sin(1/10)</m> then what can we do? We know that a calculator can work it out
<md>
<mrow>
  \sin(1/10) &amp;= 0.09983341\dots
</mrow>
</md>
but how does the calculator do this? How did people compute this before
calculators
<fn>Originally the word <q>calculator</q> referred not to the
software or electronic (or even mechanical) device we think of today, but
rather to a person who performed calculations.</fn>
? A hint comes from the
following sketch of <m>\sin(x)</m> for <m>x</m> around <m>0</m>.
</p>

<sidebyside width="50%">
<image><latex-image><![CDATA[
\begin{tikzpicture}
  \begin{axis}[
  axis x line=center, axis y line=center,
  ymax=1.05,ymin=-1.05, ytick={-1,-0.5,0.5,1.0},
  xtick={-1,-0.5,0.5,1},
  xlabel=$x$,
  legend entries={$x$,$\sin x$},
  legend pos=outer north east,
  legend style={draw=none}
  ]
  \addplot[line width=2pt, red,domain=-1:1,samples=100] {x};
  \addplot[line width=2pt, blue,domain=-1.1:1.1,samples=100] {sin(deg(x))};
  \end{axis}
\end{tikzpicture}
]]></latex-image></image>
 </sidebyside>

<p>The above figure shows that the curves <m>y=x</m> and <m>y=\sin x</m> are almost the same
when <m>x</m> is close to <m>0</m>. Hence if we want the value of
<m>\sin(1/10)</m> we could just use this approximation <m>y=x</m> to get
<md>
<mrow>
  \sin(1/10) \approx 1/10.
</mrow>
</md>
Of course, in this case we simply observed that one function was a good
approximation of the other. We need to know how to find such approximations
more systematically.
</p>

<p>More precisely, say we are given a function <m>f(x)</m> that we wish to approximate
close to some point <m>x=a</m>, and we need to find another function <m>F(x)</m>
that
 <ul>
 <li>is simple and easy to compute
 <fn>It is no good approximating a function with something that is even more difficult to work with.</fn>
 </li>
 <li>is a good approximation to <m>f(x)</m> for <m>x</m> values close to <m>a</m>.</li>
 </ul>
Further, we would like to understand how good our approximation actually is.
Namely we need to be able to estimate the error <m>|f(x)-F(x)|</m>.
</p>

<p>There are many different ways to approximate a function and we will discuss one
family of approximations: Taylor polynomials. This is an infinite family of
ever improving approximations, and our starting point is the very simplest.
</p>

</introduction>
<subsection xml:id="ssec_const_approx">
<title>Zeroth Approximation <mdash/> the Constant Approximation</title>

<p>The simplest functions are those that are constants. And our
zeroth
<fn>It barely counts as an approximation at all, but it will help
build intuition. Because of this, and the fact that a constant is a
polynomial of degree 0,  we'll start counting our approximations from zero
rather than 1.</fn>
 approximation will be by a constant function. That is, the
approximating function will have the form <m>F(x)=A</m>, for some constant <m>A</m>.
Notice that this function is a polynomial of degree zero.
</p>

<p>To ensure that <m>F(x)</m> is a good approximation for <m>x</m> close to <m>a</m>, we choose
<m>A</m> so that <m>f(x)</m> and <m>F(x)</m> take exactly the same value when <m>x=a</m>.
<md>
<mrow>
F(x)=A\qquad\text{so}\qquad F(a)=A=f(a)\implies A=f(a)
</mrow>
</md>
Our first, and crudest, approximation rule is</p>

<fact xml:id="eq_constApprox"><title>Constant approximation</title>
<statement><p>
<md>
<mrow>
f(x)\approx f(a)
</mrow>
</md>
</p></statement>
</fact>

<p>An important point to note is that we need to know <m>f(a)</m> <mdash/> if we cannot
compute that easily then we are not going to be able to proceed. We will often
have to choose <m>a</m> (the point around which we are approximating <m>f(x)</m>) with
some care to ensure that we can compute <m>f(a)</m>.
</p>

<p>Here is a figure showing the graphs of a typical <m>f(x)</m> and approximating
function <m>F(x)</m>. </p>

<sidebyside width="50%">
<image source="text/figs/approx1"/>
</sidebyside>

<p>At <m>x=a</m>, <m>f(x)</m> and <m>F(x)</m> take the same value. For <m>x</m> very near <m>a</m>,
the values of <m>f(x)</m> and <m>F(x)</m> remain close together. But the quality
of the approximation deteriorates fairly quickly as <m>x</m> moves
away from <m>a</m>. Clearly we could do better with a straight line that follows the slope of
the curve. That is our next approximation.
</p>

<p>But before then, an example:</p>
<example xml:id="eg_ex_const_approx"><title>A (weak) approximation of <m>e^{0.1}</m></title>
<p>
 Use the constant approximation to estimate <m>e^{0.1}</m>.
</p>

<p><alert>Solution</alert> First set <m>f(x) = e^x</m>.
<ul>
<li> Now we first need to pick a point <m>x=a</m>  to approximate the function. This point
needs to be close to <m>0.1</m> and we need to be able to evaluate <m>f(a)</m> easily. The obvious
choice is <m>a=0</m>.
</li>
<li> Then our constant approximation is just
<md>
<mrow>
  F(x) &amp;= f(0) = e^0 = 1
</mrow><mrow>
  F(0.1) &amp;= 1
</mrow>
</md>
</li>
</ul>
Note that <m>e^{0.1} = 1.105170918\dots</m>, so even this approximation isn't too bad..
</p></example>

</subsection>

<subsection xml:id="ssec_first_approx">
<title>First Approximation <mdash/> the Linear Approximation</title>

<p>Our first <fn>Recall that we started counting from zero.</fn>
 approximation improves on our zeroth approximation by allowing the approximating
function to be a linear function of <m>x</m> rather than just a constant function. That is, we
allow <m>F(x)</m> to be of the form <m>A+Bx</m>, for some constants <m>A</m> and <m>B</m>.
</p>

<p>To ensure that <m>F(x)</m> is a good approximation for <m>x</m> close to <m>a</m>, we still require that
<m>f(x)</m> and <m>F(x)</m> have the same value at <m>x=a</m> (that was our zeroth approximation). Our
additional requirement is that their tangent lines at <m>x=a</m> have the same slope <mdash/> that
the derivatives of <m>f(x)</m> and <m>F(x)</m> are the same at <m>x=a</m>. Hence
<md>
<mrow>
F(x)&amp;=A+Bx  &amp; &amp;\implies &amp; F(a)=A+Ba&amp;=f(a)
</mrow><mrow>
F'(x)&amp;=B    &amp; &amp;\implies &amp; F'(a)=\phantom{A+a}B&amp;=f'(a)
</mrow>
</md>
So we must have <m>B=f'(a)</m>. Substituting this into <m>A+Ba=f(a)</m> we get
<m>A=f(a)-af'(a)</m>. So
we can write
<md>
<mrow>
  F(x) &amp;= A+Bx = \overbrace{f(a)- af'(a)}^A+ f'(a) \cdot x
</mrow><mrow>
  &amp;= f(a) + f'(a) \cdot(x-a)
</mrow>
</md>
We write it in this form because we can now clearly see that our first approximation is
just an extension of our zeroth approximation. This first approximation is also often
called the linear approximation of <m>f(x)</m> about <m>x=a</m>.</p>

<fact xml:id="eq_linApprox"><title>Linear approximation</title>
<statement><p>
<md>
<mrow>
  f(x) \approx f(a)+f'(a)(x-a)
</mrow>
</md>
</p></statement>
</fact>
<p> We should again stress that in order to form this approximation we need to know
<m>f(a)</m> and <m>f'(a)</m> <mdash/> if we cannot compute them easily then we are not going to be able
to proceed.
</p>

<p>Recall, from Theorem <xref ref="thm_DIFFtangentLine"/>, that <m>y=f(a)+f'(a)(x-a)</m>
is exactly the equation of the tangent line to the curve <m>y=f(x)</m> at <m>a</m>.
Here is a figure showing the graphs of a typical <m>f(x)</m> and the approximating
function <m>F(x)</m>.</p>

<sidebyside width="66%">
<image source="text/figs/approx2"/>
</sidebyside>

<p> Observe that the graph of <m>f(a)+f'(a)(x-a)</m> remains close to the
graph of <m>f(x)</m> for a much larger range of <m>x</m> than did the graph of our constant
approximation, <m>f(a)</m>. One can also see that we can improve this approximation if we can
use a function that curves down rather than being perfectly straight. That is our next
approximation.
</p>

<p>But before then, back to our example:</p>
<example><title>A better approximation of <m>e^{0.1}</m></title>
<p>
 Use the linear approximation to estimate <m>e^{0.1}</m>.
</p>

<p><alert>Solution</alert> First set <m>f(x) = e^x</m> and <m>a=0</m> as before.
<ul>
<li> To form the linear approximation we need <m>f(a)</m> and <m>f'(a)</m>:
<md>
<mrow>
  f(x) &amp;= e^x &amp; f(0) &amp; = 1
</mrow><mrow>
  f'(x) &amp;= e^x &amp; f'(0) &amp; = 1
</mrow>
</md>
</li>
<li> Then our linear approximation is
<md>
<mrow>
  F(x) &amp;= f(0) + x f'(0) = 1 + x
</mrow><mrow>
  F(0.1) &amp;= 1.1
</mrow>
</md>
</li>
</ul>
Recall that <m>e^{0.1} = 1.105170918\dots</m>, so the linear approximation is
almost correct to 3 digits.
</p></example>


<p>It is worth doing another simple example here.</p>
<example><title>A linear approximation of <m>\sqrt{4.1}</m></title>
<p>
 Use a linear approximation to estimate <m>\sqrt{4.1}</m>.
</p>

<p><alert>Solution</alert> First set <m>f(x)=\sqrt{x}</m>. Hence <m>f'(x) = \frac{1}{2\sqrt{x}}</m>. Then we are trying
to approximate <m>f(4.1)</m>. Now we need to choose a sensible <m>a</m> value.
<ul>
<li><p> We need to choose <m>a</m> so that <m>f(a)</m> and <m>f'(a)</m> are easy to compute.
<ul>
<li> We could try <m>a=4.1</m> <mdash/> but then we need to compute <m>f(4.1)</m> and <m>f'(4.1)</m> <mdash/>
which is our original problem and more!
</li>
<li> We could try <m>a=0</m> <mdash/> then <m>f(0)=0</m> and <m>f'(0) = DNE</m>.
</li>
<li> Setting <m>a=1</m> gives us <m>f(1)=1</m> and <m>f'(1)=\frac{1}{2}</m>. This would work, but we
can get a better approximation by choosing <m>a</m> is closer to <m>4.1</m>.
</li>
<li> Indeed we can set <m>a</m> to be the square of any rational number and we'll get a
result that is easy to compute.
</li>
<li> Setting <m>a=4</m> gives <m>f(4)=2</m> and <m>f'(4) = \frac{1}{4}</m>. This seems good enough.
</li>
</ul>
</p></li>
<li> Substitute this into equation<nbsp/><xref ref="eq_linApprox"/> to get
<md>
<mrow>
  f(4.1) &amp;\approx f(4) + f'(4) \cdot(4.1-4)
</mrow><mrow>
  &amp;= 2 + \frac{0.1}{4} = 2 + 0.025 = 2.025
</mrow>
</md>
</li>
</ul>
Notice that the true value is <m>\sqrt{4.1} = 2.024845673\dots</m>.
</p></example>

</subsection>

<subsection xml:id="ssec_second_approx">
<title>Second Approximation <mdash/> the Quadratic Approximation</title>

<p>We next develop a still better approximation by now allowing the
approximating function be to a quadratic function of <m>x</m>. That is,
we allow <m>F(x)</m> to be of the form <m>A+Bx+Cx^2</m>, for some constants <m>A</m>, <m>B</m>
and <m>C</m>. To ensure that <m>F(x)</m> is a good approximation for <m>x</m> close
to <m>a</m>, we choose <m>A</m>, <m>B</m> and <m>C</m> so that
<ul>
<li> <m>f(a)=F(a)</m>  (just as in our zeroth approximation),
</li>
<li> <m>f'(a)=F'(a)</m>  (just as in our first approximation), and
</li>
<li> <m>f''(a)=F''(a)</m> <mdash/> this is a new condition.
</li>
</ul>
These conditions give us the following equations
<md>
<mrow>
F(x)&amp;=A+Bx+Cx^2  &amp; &amp;\implies &amp; F(a)=A+Ba+\phantom{2}Ca^2&amp;=f(a)
</mrow><mrow>
F'(x)&amp;=B+2Cx &amp; &amp;\implies &amp; F'(a)=\phantom{A+a}B+2Ca&amp;=f'(a)
</mrow><mrow>
F''(x)&amp;=2C   &amp; &amp;\implies &amp; F''(a)=\phantom{A+aB+a}2C&amp;=f''(a)
</mrow>
</md>
Solve these for <m>C</m> first, then <m>B</m> and finally <m>A</m>.
<md>
<mrow>
C &amp;=\half f''(a) &amp; \text{substitute}
</mrow><mrow>
B &amp;= f'(a) - 2Ca = f'(a)-af''(a) &amp; \text{substitute again}
</mrow><mrow>
A &amp;= f(a)-Ba-Ca^2 = f(a)-a[f'(a)-af''(a)]-\half f''(a)a^2\hskip-0.5in
</mrow>
</md>
Then put things back together to build up <m>F(x)</m>:
<md>
<mrow>
F(x)&amp;=f(a)-f'(a)a+\half f''(a)a^2 &amp; &amp;\text{(this line is $A$)}\cr
&amp;\phantom{=f(a)\hskip3pt}+f'(a)\,x\hskip3pt- f''(a)ax
   &amp; &amp; \text{(this line is $Bx$)}
</mrow><mrow>
&amp;\phantom{=f(a)-f'(a)a\hskip3.5pt}+\half f''(a)x^2
 &amp; &amp;\text{(this line is $Cx^2$)}
</mrow><mrow>
&amp;=f(a)+f'(a)(x-a)+\half f''(a)(x-a)^2
</mrow>
</md>
Oof! We again write it in this form because we can now clearly see that our second
approximation is just an extension of our first approximation.
</p>

<p>Our second approximation is called the quadratic approximation:</p>

<fact xml:id="eq_quadApprox"><title>Quadratic approximation</title>
<statement><p>
<md>
<mrow>
f(x)\approx f(a)+f'(a)(x-a)+\half f''(a)(x-a)^2
</mrow>
</md>
</p></statement>
</fact>

<p> Here is a figure showing the graphs of a typical <m>f(x)</m> and approximating function <m>F(x)</m>.</p>

<sidebyside width="95%">
<image source="text/figs/approx3"/>
</sidebyside>

<p>This new approximation looks better than both the first and second.</p>

<p>Now there is actually an easier way to derive this approximation, which we show
you now. Let us rewrite
<fn>Any polynomial of degree two can be written in
this form. For example, when <m>a=1</m>, <m>3 + 2x + x^2 =   6 +  4(x-1) + (x-1)^2</m>.</fn>
</p>

<p><m>F(x)</m> so that it is easy to evaluate it and its derivatives at <m>x=a</m>:
<md>
<mrow>
  F(x) &amp;= \alpha + \beta\cdot (x-a) + \gamma \cdot(x-a)^2
</mrow>
</md>
Then
<md>
<mrow>
  F(x) &amp;= \alpha + \beta\cdot (x-a) + \gamma \cdot(x-a)^2 &amp;
  F(a) &amp;= \alpha = f(a)
</mrow><mrow>
  F'(x) &amp;= \beta + 2\gamma \cdot(x-a) &amp;
  F'(a)&amp;=\beta = f'(a)
</mrow><mrow>
  F''(x) &amp;= 2\gamma &amp;
  F''(a) &amp;= 2\gamma = f''(a)
</mrow>
</md>
And from these we can clearly read off the values of <m>\alpha,\beta</m> and <m>\gamma</m> and so
recover our function <m>F(x)</m>. Additionally if we write things this way, then it is quite
clear how to extend this to a cubic approximation and a quartic approximation and so
on.
</p>

<p>Return to our example:</p>
<example><title>An even better approximation of <m> e^{0.1}</m></title>
<p>
 Use the quadratic approximation to estimate <m>e^{0.1}</m>.
</p>

<p><alert>Solution</alert> Set <m>f(x) = e^x</m> and <m>a=0</m> as before.
<ul>
<li> To form the quadratic approximation we need <m>f(a), f'(a)</m> and <m>f''(a)</m>:
<md>
<mrow>
  f(x) &amp;= e^x &amp; f(0) &amp; = 1
</mrow><mrow>
  f'(x) &amp;= e^x &amp; f'(0) &amp; = 1
</mrow><mrow>
  f''(x) &amp;= e^x &amp; f''(0) &amp; = 1
</mrow>
</md>
</li>
<li> Then our quadratic approximation is
<md>
<mrow>
  F(x) &amp;= f(0) + x f'(0)  + \frac{1}{2} x^2 f''(0) = 1 + x + \frac{x^2}{2}
</mrow><mrow>
  F(0.1) &amp;= 1.105
</mrow>
</md>
</li>
</ul>
Recall that <m>e^{0.1} = 1.105170918\dots</m>, so the quadratic approximation is quite
accurate with very little effort.
</p></example>

<p>Before we go on, let us first introduce (or revise) some notation that will make our
discussion easier.
</p>

</subsection>

<subsection xml:id="ssec_sigma">
<title>Whirlwind Tour of Summation Notation</title>

<p>In the remainder of this section we will frequently need to write sums involving a
large number of terms. Writing out the summands explicitly can become quite
impractical <mdash/> for example, say we need the sum of the first 11 squares:
<md>
<mrow>
  1 + 2^2 + 3^2 + 4^2+ 5^2 + 6^2 + 7^2 + 8^2 + 9^2 + 10^2 + 11^2
</mrow>
</md>
This becomes tedious. Where the pattern is clear, we will often skip the middle few
terms and instead write
<md>
<mrow>
  1 + 2^2 + \cdots  + 11^2.
</mrow>
</md>
A far more precise way to write this is using <m>\Sigma</m> (capital-sigma) notation. For
example, we can write the above sum as
<md>
<mrow>
  \sum_{k=1}^{11} k^2
</mrow>
</md>
This is read as </p>

<blockquote>
<p>
 The sum from <m>k</m> equals 1 to 11 of <m>k^2</m>.
</p>
</blockquote>

<p>More generally</p>
<definition>
<statement><p>
Let <m>m\leq n</m> be integers and let <m>f(x)</m> be a function defined on the integers.
Then we write
<md>
<mrow>
  \sum_{k=m}^n f(k)
</mrow>
</md>
to mean the sum of <m>f(k)</m> for <m>k</m> from <m>m</m> to <m>n</m>:
<md>
<mrow>
  f(m) + f(m+1) + f(m+2) + \cdots + f(n-1) + f(n).
</mrow>
</md>
Similarly we write
<md>
<mrow>
  \sum_{i=m}^n a_i
</mrow>
</md>
to mean
<md>
<mrow>
  a_m+a_{m+1}+a_{m+2}+\cdots+a_{n-1}+a_n
</mrow>
</md>
for some set of coefficients <m>\{ a_m, \ldots, a_n \}</m>.
</p></statement>
</definition>


<p>Consider the example
<md>
<mrow>
\sum_{k=3}^7 \frac{1}{k^2}=\frac{1}{3^2}+\frac{1}{4^2}+\frac{1}{5^2}+
\frac{1}{6^2}+\frac{1}{7^2}
</mrow>
</md>
It is important to note that the right hand side of this expression evaluates to a
number
<fn>Some careful addition shows it is <m>\frac{46181}{176400}</m>.</fn>; it does not
contain <q><m>k</m></q>.  The summation index <m>k</m>  is just a <q>dummy</q> variable and
it does not have to be called <m>k</m>. For example
<md>
<mrow>
  \sum_{k=3}^7 \frac{1}{k^2}
  =\sum_{i=3}^7 \frac{1}{i^2}
  =\sum_{j=3}^7 \frac{1}{j^2}
  =\sum_{\ell=3}^7 \frac{1}{\ell^2}
</mrow>
</md>
Also the summation index has no meaning outside the sum. For
example
<md>
<mrow>
k\sum_{k=3}^7 \frac{1}{k^2}
</mrow>
</md>
has no mathematical meaning; It is gibberish
<fn>Or possibly gobbledygook. For a discussion of statements without meaning and why one should avoid them we recommend the
book <q>Bendable learnings: the wisdom of modern management</q> by Don Watson.</fn>
.
</p>
</subsection>



<subsection xml:id="ssec_taylor_poly">
<title>Still Better Approximations <mdash/> Taylor Polynomials</title>

<p>We can use the same strategy to generate still better approximations by
polynomials
<fn>Polynomials are generally a good choice for an approximating
function since they are so easy to work with. Depending on the situation other families
of functions may be more appropriate. For example if you are approximating a periodic
function, then sums of sines and cosines might be a better choice; this leads to Fourier
series.</fn>
 of any degree we like. As was the case with the approximations above, we
determine the coefficients of the polynomial by requiring, that at the point
<m>x=a</m>, the approximation and its first <m>n</m> derivatives agree with those of the
original function.
</p>

<p>Rather than simply moving to a cubic polynomial, let us try to write things in a more
general way. We will consider approximating the function <m>f(x)</m> using a polynomial,
<m>T_n(x)</m>, of degree <m>n</m> <mdash/> where <m>n</m> is a non-negative integer. As we discussed
above, the algebra is easier if we write
<md>
<mrow>
  T_n(x) &amp;= c_0 + c_1(x-a) + c_2 (x-a)^2 + \cdots + c_n (x-a)^n
</mrow><mrow>
  &amp;= \sum_{k=0}^n c_k (x-a)^k &amp; \text{using } \Sigma \text{ notation}
</mrow>
</md>
The above form
<fn>Any polynomial in <m>x</m> of degree <m>n</m> can also be
expressed as a polynomial in <m>(x-a)</m> of the same degree <m>n</m> and vice versa.  So
<m>T_n(x)</m> really still is a polynomial of degree <m>n</m>.</fn>
<fn>Furthermore
when <m>x</m> is close to <m>a</m>, <m>(x-a)^k</m> decreases very quickly as <m>k</m> increases,
which often makes the "high <m>k</m>" terms in <m>T_n(x)</m> very small. This can be a
considerable advantage when building up approximations by adding more and more
terms.  If we were to rewrite  <m>T_n(x)</m> in the form <m>\ds \sum_{k=0}^n b_k x^k</m>
the "high <m>k</m>" terms would typically not be very small when <m>x</m> is close to
<m>a</m>.</fn> makes it very easy to evaluate this polynomial and its derivatives at
<m>x=a</m>. Before we proceed, we remind the reader of some notation (see
Notation<nbsp/><xref ref="notn_higher_diff"/>):
<ul>
<li> Let <m>f(x)</m> be a function and <m>k</m> be a positive integer. We can denote
its <m>k^\mathrm{th}</m> derivative with respect to <m>x</m> by
<md>
<mrow>
  \ddiff{k}{f}{x} &amp;&amp; \left( \diff{}{x}\right)^k f(x) &amp;&amp; f^{(k)}(x)
</mrow>
</md>
</li>
</ul>
</p>

<p>Additionally we will need</p>
<definition><title>Factorial</title>
<statement><p>
  Let <m>n</m> be a positive integer
<fn>It is actually possible to define the
factorial of positive real numbers and even negative numbers but it requires more
advanced calculus and is outside the scope of this course. The interested reader should
look up the Gamma function.</fn>
, then <m>n</m>-factorial, denoted <m>n!</m>, is the product
  <md>
<mrow>
    n! &amp;= n \times (n-1) \times \cdots \times 3 \times 2 \times 1
  </mrow>
</md>
  Further, we use the convention that
  <md>
<mrow>
  0! &amp;= 1
  </mrow>
</md>
  The first few factorials are
<md>
<mrow>
  1! &amp;=1 &amp;
  2! &amp;=2 &amp;
  3! &amp;=6
</mrow><mrow>
  4! &amp;=24 &amp;
  5! &amp;=120 &amp;
  6! &amp;=720
</mrow>
</md>
</p></statement>
</definition>

<p>Now consider <m>T_n(x)</m> and its derivatives:
<md alignment="alignat">
<mrow>
  T_n(x) &amp;=&amp; c_0 &amp;+ c_1(x-a) &amp; + c_2 (x-a)^2 &amp; + c_3(x-a)^3 &amp;+ \cdots+ &amp; c_n (x-a)^n
</mrow><mrow>
  T_n'(x) &amp;=&amp;  &amp;c_1 &amp; + 2 c_2 (x-a) &amp; + 3c_3(x-a)^2 &amp;+ \cdots +&amp;  n c_n (x-a)^{n-1}
</mrow><mrow>
  T_n''(x) &amp;=&amp;  &amp;  &amp; 2 c_2 &amp; + 6c_3(x-a) &amp;+ \cdots +&amp;  n(n-1) c_n (x-a)^{n-2}
</mrow><mrow>
  T_n'''(x) &amp;=&amp;  &amp;  &amp; &amp; 6c_3 &amp;+ \cdots + &amp;  n(n-1)(n-2) c_n (x-a)^{n-3}
</mrow><mrow>
  &amp; \vdots
</mrow><mrow>
  T_n^{(n)}(x) &amp;=&amp;  &amp;  &amp; &amp; &amp; &amp;  n! \cdot c_n
</mrow>
</md>
Now notice that when we substitute <m>x=a</m> into the above expressions only the constant
terms survive and we get
<md>
<mrow>
  T_n(a) &amp;= c_0
</mrow><mrow>
  T_n'(a) &amp;= c_1
</mrow><mrow>
  T_n''(a) &amp;= 2\cdot c_2
</mrow><mrow>
  T_n'''(a) &amp;= 6 \cdot c_3
</mrow><mrow>
  &amp;\vdots
</mrow><mrow>
  T_n^{(n)}(a) &amp;= n! \cdot c_n
</mrow>
</md>
</p>

<p>So now if we want to set the coefficients of <m>T_n(x)</m> so that it agrees with
<m>f(x)</m>  at <m>x=a</m> then we need
<md>
<mrow>
  T_n(a) &amp;= c_0 = f(a) &amp; c_0 &amp;= f(a) = \frac{1}{0!} f(a)
</mrow>
<intertext>We also want the first <m>n</m> derivatives of <m>T_n(x)</m> to agree with the
derivatives of <m>f(x)</m> at <m>x=a</m>, so</intertext><mrow>
  T_n'(a) &amp;= c_1 = f'(a) &amp; c_1 &amp;= f'(a) = \frac{1}{1!} f'(a)
</mrow><mrow>
  T_n''(a) &amp;= 2\cdot c_2 = f''(a) &amp; c_2 &amp;= \frac{1}{2} f''(a) = \frac{1}{2!}f''(a)
</mrow><mrow>
  T_n'''(a) &amp;= 6\cdot c_3 = f'''(a) &amp; c_3 &amp;= \frac{1}{6} f'''(a) = \frac{1}{3!} f'''(a)
</mrow>
<intertext>More generally, making the <m>k^\mathrm{th}</m> derivatives agree at <m>x=a</m> requires
:</intertext><mrow>
  T_n^{(k)}(a) &amp;= k!\cdot c_k = f^{(k)}(a) &amp; c_k &amp;= \frac{1}{k!} f^{(k)}(a)
</mrow>
<intertext>And finally the <m>n^\mathrm{th}</m> derivative:</intertext><mrow>
  T_n^{(n)}(a) &amp;= n!\cdot c_n = f^{(n)}(a) &amp; c_n &amp;= \frac{1}{n!} f^{(n)}(a)
</mrow>
</md>
Putting this all together we have</p>

<fact xml:id="eq_taylorPoly"><title>Taylor polynomial</title>
<statement><p>
 <md>
<mrow>
  f(x) \approx T_n(x)
  &amp;= f(a) + f'(a) (x-a) + \frac{1}{2} f''(a) \cdot(x-a)^2 + \cdots 
  </mrow><mrow>
           \amp\hskip2in+ \frac{1}{n!}f^{(n)}(a) \cdot (x-a)^n
</mrow><mrow>
  &amp;= \sum_{k=0}^n \frac{1}{k!} f^{(k)}(a) \cdot (x-a)^k
 </mrow>
</md>
</p></statement>
</fact>

<p>Let us formalise this definition.</p>
<definition><title>Taylor polynomial</title>
<statement><p>
  Let <m>a</m> be a constant and let <m>n</m> be a non-negative integer. The <m>n^\mathrm{th}</m>
degree Taylor polynomial for <m>f(x)</m> about <m>x=a</m> is
<md>
<mrow>
  T_n(x) &amp;= \sum_{k=0}^n \frac{1}{k!} f^{(k)}(a) \cdot (x-a)^k.
</mrow>
</md>
  The special case <m>a=0</m> is called a Maclaurin
<fn>The polynomials are named after
Brook Taylor who devised a general method for constructing them in 1715. Slightly
later, Colin Maclaurin made extensive use of the special case <m>a=0</m> (with attribution of
the general case to Taylor) and it is now named after him. The special case of
<m>a=0</m> was worked on previously by James Gregory and Isaac Newton, and some
specific cases were known to the 14th century Indian mathematician Madhava of
Sangamagrama.</fn>
 polynomial.
</p></statement>
</definition>

<p>Before we proceed with some examples, a couple of remarks are in order.
<ul>
<li> While we can compute a Taylor polynomial about any <m>a</m>-value (providing the
derivatives exist), in order to be a <em>useful</em> approximation, we must be able to
compute <m>f(a),f'(a),\cdots,f^{(n)}(a)</m> easily. This means we must choose the point <m>a</m>
with care. Indeed for many functions the choice <m>a=0</m> is very natural <mdash/> hence the
prominence of Maclaurin polynomials.
</li>
<li> If we have computed the approximation <m>T_n(x)</m>, then we can readily
extend this to the next Taylor polynomial <m>T_{n+1}(x)</m> since
<md>
<mrow>
  T_{n+1}(x) &amp;= T_n(x) + \frac{1}{(n+1)!} f^{(n+1)}(a) \cdot (x-a)^{n+1}
</mrow>
</md>
This is very useful if we discover that <m>T_n(x)</m> is an insufficient
approximation, because then we can produce <m>T_{n+1}(x)</m> without having to start
again from scratch.
</li>
</ul>
</p>

</subsection>

<subsection xml:id="ssec_taylor_eg">
<title>Some Examples</title>

<p>Let us return to our running example of <m>e^x</m>:</p>
<example xml:id="eg_taylor_e_to_the_x"><title>Taylor approximations of <m>e^x</m></title>
<p>
 The constant, linear and quadratic approximations we used above were the first few
Maclaurin polynomial approximations of <m>e^x</m>. That is
<md>
<mrow>
  T_0 (x) &amp; = 1 &amp; T_1(x) &amp;= 1+x &amp; T_2(x) &amp;= 1+x+\frac{x^2}{2}
</mrow>
</md>
Since <m>\diff{}{x} e^x = e^x</m>, the Maclaurin polynomials are very easy to compute.
Indeed this invariance under differentiation means that
<md>
<mrow>
  f^{(n)}(x) &amp;= e^x &amp; n=0,1,2,\dots &amp;&amp; \text{so}
</mrow><mrow>
  f^{(n)}(0) &amp;= 1
</mrow>
</md>
Substituting this into equation<nbsp/><xref ref="eq_taylorPoly"/> we get
<md>
<mrow>
  T_n(x) &amp;= \sum_{k=0}^n \frac{1}{k!} x^k
</mrow>
</md>
Thus we can write down the seventh Maclaurin polynomial very easily:
<md>
<mrow>
  T_7(x) &amp;= 1 + x + \frac{x^2}{2} + \frac{x^3}{6} + \frac{x^4}{24} + \frac{x^5}{120} +
\frac{x^6}{720} + \frac{x^7}{5040}
</mrow>
</md>
Also notice that if we use this to approximate the value of <m>e^1</m> we obtain:
<md>
<mrow>
  e^1 \approx T_7(1) &amp;= 1 + 1 + \frac{1}{2} + \frac{1}{6} + \frac{1}{24} + \frac{1}{120}
+ \frac{1}{720} + \frac{1}{5040}
</mrow><mrow>
  &amp;= \frac{685}{252} =  2.718253968\dots
</mrow>
</md>
The true value of <m>e</m> is <m>2.718281828\dots</m>, so the approximation has an error of about
<m>3\times10^{-5}</m>.
</p>

<p>Under the assumption that the accuracy of the approximation improves with
<m>n</m> (an assumption we examine in Subsection<nbsp/><xref ref="ssec_taylor_error"/> below) we can see
that the approximation of <m>e</m> above can be improved by adding more and more terms. Indeed
this is how the expression for <m>e</m> in equation<nbsp/><xref ref="eq_eulerconst"/> in
Section<nbsp/><xref ref="sec_exp_func"/> comes about.
</p>

</example>
<p> Now that we have examined Maclaurin polynomials for <m>e^x</m> we should take a look at <m>\log
x</m>. Notice that we cannot compute a Maclaurin polynomial for <m>\log x</m> since it is not
defined at <m>x=0</m>.</p>

<example xml:id="eg_expand_logx"><title>Taylor approximation of <m>\log x</m></title>
<p>
Compute the <m>5^\mathrm{th}</m> Taylor polynomial for <m>\log x</m> about <m>x=1</m>.
</p>

<p><alert>Solution</alert> We have been told <m>a=1</m> and fifth degree, so we should start by writing down the
function and its first five derivatives:
<md>
<mrow>
  f(x) &amp;= \log x &amp; f(1) &amp;= \log 1 = 0
</mrow><mrow>
  f'(x) &amp;= \frac{1}{x} &amp; f'(1) &amp;= 1
</mrow><mrow>
  f''(x) &amp;= \frac{-1}{x^2} &amp; f''(1) &amp;= -1
</mrow><mrow>
  f'''(x) &amp;= \frac{2}{x^3} &amp; f'''(1) &amp;= 2
</mrow><mrow>
  f^{(4)}(x) &amp;= \frac{-6}{x^4} &amp; f^{(4)}(1) &amp;= -6
</mrow><mrow>
  f^{(5)}(x) &amp;= \frac{24}{x^5} &amp; f^{(5)}(1) &amp;= 24
</mrow>
</md>
Substituting this into equation<nbsp/><xref ref="eq_taylorPoly"/> gives
<md>
<mrow>
  T_5(x)&amp;= 0 + 1\cdot (x-1)
  + \frac{1}{2} \cdot (-1) \cdot (x-1)^2
  + \frac{1}{6} \cdot 2 \cdot (x-1)^3
  </mrow><mrow>
  \amp\hskip0.5in+ \frac{1}{24} \cdot (-6) \cdot (x-1)^4
  + \frac{1}{120} \cdot 24 \cdot (x-1)^5
</mrow><mrow>
  &amp;= (x-1) - \frac{1}{2}(x-1)^2 + \frac{1}{3}(x-1)^3 - \frac{1}{4}(x-1)^4 +
\frac{1}{5}(x-1)^5
</mrow>
</md>
Again, it is not too hard to generalise the above work to find the Taylor polynomial of
degree <m>n</m>:
With a little work one can show that
<md>
<mrow>
  T_n(x) &amp;= \sum_{k=1}^n \frac{(-1)^{k+1}}{k} (x-1)^k.
</mrow>
</md>
</p>
</example>
<p>For cosine:</p>
<example xml:id="eg_expand_cosx"><title>Maclaurin polynomial for <m>\cos x</m></title>
<p>
 Find the 4th degree Maclaurin polynomial for <m>\cos x</m>.
</p>

<p><alert>Solution</alert> We have <m>a=0</m> and we need to find the first 4 derivatives of <m>\cos x</m>.
<md>
<mrow>
 f(x) &amp;= \cos x &amp; f(0) &amp;= 1
</mrow><mrow>
 f'(x) &amp;= -\sin x &amp; f'(0) &amp;= 0
</mrow><mrow>
 f''(x) &amp;= -\cos x &amp; f''(0) &amp;= -1
</mrow><mrow>
 f'''(x) &amp;= \sin x &amp; f'''(0) &amp;= 0
</mrow><mrow>
 f^{(4)}(x) &amp;= \cos x &amp; f^{(4)}(0) &amp;= 1
</mrow>
</md>
Substituting this into equation<nbsp/><xref ref="eq_taylorPoly"/> gives
<md>
<mrow>
  T_4(x)&amp;= 1 + 1\cdot (0) \cdot x
  + \frac{1}{2} \cdot (-1) \cdot x^2
  + \frac{1}{6} \cdot 0 \cdot x^3
  + \frac{1}{24} \cdot (1) \cdot x^4
</mrow><mrow>
  &amp;= 1 - \frac{x^2}{2} + \frac{x^4}{24}
</mrow>
</md>
Notice that since the <m>4^\mathrm{th}</m> derivative of <m>\cos x</m> is <m>\cos x</m> again, we also
have that the fifth derivative is the same as the first derivative, and the sixth
derivative is the same as the second derivative and so on. Hence the next four
derivatives are
<md>
<mrow>
 f^{(4)}(x) &amp;= \cos x &amp; f^{(4)}(0) &amp;= 1
</mrow><mrow>
 f^{(5)}(x) &amp;= -\sin x &amp; f^{(5)}(0) &amp;= 0
</mrow><mrow>
 f^{(6)}(x) &amp;= -\cos x &amp; f^{(6)}(0) &amp;= -1
</mrow><mrow>
 f^{(7)}(x) &amp;= \sin x &amp; f^{(7)}(0) &amp;= 0
</mrow><mrow>
 f^{(8)}(x) &amp;= \cos x &amp; f^{(8)}(0) &amp;= 1
</mrow>
</md>
Using this we can find the <m>8^\mathrm{th}</m> degree Maclaurin polynomial:
<md>
<mrow>
  T_8(x) &amp;=
  1 - \frac{x^2}{2} + \frac{x^4}{24} -\frac{x^6}{6!} + \frac{x^8}{8!}
</mrow>
</md>
Continuing this process gives us the <m>2n^\mathrm{th}</m> Maclaurin polynomial
<md>
<mrow>
  T_{2n}(x) &amp;= \sum_{k=0}^n \frac{(-1)^k}{(2k)!} \cdot x^{2k}
</mrow>
</md>
</p>
<warning>
<statement><p>
The above formula only works when x is measured in radians, because all of our
derivative formulae for trig functions were developed under the assumption that
angles are measured in radians.
</p></statement>
</warning>

<p>Below we plot <m>\cos x</m> against its first few Maclaurin polynomial
approximations:</p>
<sidebyside widths="40% 40%">
<image source="text/figs/approx1d"/>
  <image source="text/figs/approx2d"/>
</sidebyside>
<sidebyside widths="40% 40%">
<image source="text/figs/approx3d"/>
  <image source="text/figs/approx4d"/>
</sidebyside>

</example>

<p>The above work is quite easily recycled to get the Maclaurin polynomial for sine:</p>

<example xml:id="eg_expand_sinx"><title>Maclaurin polynomial for <m>\sin x</m></title>
<p>
 Find the 5th degree Maclaurin polynomial for <m>\sin x</m>.
</p>

<p><alert>Solution</alert> We could simply work as before and compute the first five derivatives of <m>\sin x</m>.
But set <m>g(x) = \sin x</m> and notice that <m>g(x) = - f'(x)</m>, where <m>f(x) =\cos x</m>. Then we
have
<md>
<mrow>
  g(0) &amp;= -f'(0) = 0
</mrow><mrow>
  g'(0) &amp;= -f''(0) = 1
</mrow><mrow>
  g''(0) &amp;= -f'''(0) = 0
</mrow><mrow>
  g'''(0) &amp;= -f^{(4)}(0) = -1
</mrow><mrow>
  g^{(4)}(0) &amp;= -f^{(5)}(0) = 0
</mrow><mrow>
  g^{(5)}(0) &amp;= -f^{(6)}(0) = 1
</mrow>
</md>
Hence the required Maclaurin polynomial is
<md>
<mrow>
  T_5(x) &amp;= x - \frac{x^3}{3!} + \frac{x^5}{5!}
</mrow>
</md>
Just as we extended to the <m>2n^\mathrm{th}</m> Maclaurin polynomial for cosine, we can also
extend our work to compute the <m>(2n+1)^\mathrm{th}</m> Maclaurin polynomial for sine:
<md>
<mrow>
  T_{2n+1}(x) &amp;= \sum_{k=0}^n \frac{(-1)^k}{(2k+1)!} \cdot x^{2k+1}
</mrow>
</md>
</p>
<warning>
<statement><p>
The above formula only works when x is measured in radians, because all of our
derivative formulae for trig functions were developed under the assumption that
angles are measured in radians.
</p></statement>
</warning>

<p>Below we plot <m>\sin x</m> against its first few Maclaurin polynomial approximations.</p>

<sidebyside widths="40% 40%">
<image source="text/figs/approx1c"/>
  <image source="text/figs/approx2c"/>
</sidebyside>
<sidebyside widths="40% 40%">
<image source="text/figs/approx3c"/>
  <image source="text/figs/approx4c"/>
</sidebyside>

</example>

<p>To get an idea of how good these Taylor polynomials are at approximating <m>\sin</m> and
<m>\cos</m>, let's concentrate on <m>\sin x</m> and consider <m>x</m>'s whose magnitude <m>|x|\le 1</m>.
There are tricks that you can employ
<fn>If you are writing software to evaluate
<m>\sin x</m>, you can always use the trig identity <m>\sin(x)=\sin(x-2n\pi)</m>, to  easily
restrict to <m>|x|\le\pi</m>. You can then use the trig identity <m>\sin(x)=-\sin(x\pm\pi)</m> to
reduce to <m>|x|\le\tfrac{\pi}{2}</m>. Finally you can use the trig identity
<m>\sin(x)=\mp\cos(\tfrac{\pi}{2}\pm x))</m> to reduce to <m>|x|\le\tfrac{\pi}{4}  \lt  1</m>.</fn> to
evaluate sine and cosine at values of <m>x</m> outside this range.
</p>

<p>If <m>|x|\le 1</m> radians
<fn>Recall that the derivative formulae that we used to
derive the Taylor polynomials are valid only when <m>x</m> is in radians. The
restriction <m>-1 \leq x \leq 1</m> radians translates to angles bounded by
<m>\tfrac{180}{\pi}\approx 57^\circ</m>.</fn>, then the magnitudes of the successive
terms in the Taylor polynomials for <m>\sin x</m> are bounded by
<md alignment="alignat">
<mrow>
|x|&amp;\le 1 &amp;
\tfrac{1}{3!}|x|^3&amp;\le\tfrac{1}{6} &amp;
\tfrac{1}{5!}|x|^5&amp;\le\tfrac{1}{120}\approx 0.0083
</mrow><mrow>
\tfrac{1}{7!}|x|^7&amp;\le\tfrac{1}{7!}\approx 0.0002\quad &amp;
\tfrac{1}{9!}|x|^9&amp;\le\tfrac{1}{9!}\approx 0.000003\quad &amp;
\tfrac{1}{11!}|x|^{11}&amp;\le\tfrac{1}{11!}\approx 0.000000025
</mrow>
</md>
From these inequalities, and the graphs on the previous pages, it certainly looks like,
for <m>x</m> not too large, even relatively low degree Taylor polynomials give very good
approximations. In Section<nbsp/><xref ref="ssec_taylor_error"/> we'll see how to get rigorous error
bounds on our Taylor polynomial approximations.
</p>

</subsection>

<subsection xml:id="ssec_est_change">
<title>Estimating Change and <m>\De x</m>, <m>\De y</m> Notation</title>

<p>Suppose that we have two variables <m>x</m> and <m>y</m> that are related by <m>y=f(x)</m>, for some
function <m>f</m>. One of the most important applications of calculus is to help us understand
what happens to <m>y</m> when we make a small change in <m>x</m>.
</p>

<definition>
<statement><p>
 Let <m>x,y</m> be variables related by a function <m>f</m>. That is <m>y = f(x)</m>. Then we denote a
  small change in the variable <m>x</m> by <m>\De x</m> (read as <q>delta <m>x</m></q>). The corresponding
small change in the variable <m>y</m> is denoted <m>\De y</m> (read as <q>delta <m>y</m></q>).
<md>
<mrow>
  \De y &amp;= f(x+\De x) - f(x)
</mrow>
</md>
</p></statement>
</definition>

<p>In many situations we do not need to compute <m>\De y</m> exactly and are instead happy with
an approximation. Consider the following example.</p>

<example><title>Estimate the increase in cost for a given change in production</title>
<p>
Let <m>x</m> be the number of cars manufactured per week in some factory and let <m>y</m> the cost
of manufacturing those <m>x</m> cars. Given that the factory currently produces <m>a</m> cars per
week, we would like to estimate the increase in cost if we make a small change in the
number of cars produced.
</p>

<p><alert>Solution</alert> We are told that <m>a</m> is the number of cars currently produced per week; the cost
of production  is then <m>f(a)</m>.
<ul>
<li> Say the number of cars produced is changed from <m>a</m> to <m>a+\De x</m> (where <m>\De x</m>
is some small number.
</li>
<li> As <m>x</m> undergoes this change, the costs change from <m>y=f(a)</m> to <m>f(a+\De x)</m>.
Hence
<md>
<mrow>
  \De y &amp;= f(a+\De x) - f(a)
</mrow>
</md>
</li>
<li><p> We can estimate this change using a linear approximation. Substituting
<m>x=a+\De x</m> into the equation<nbsp/><xref ref="eq_linApprox"/> yields the approximation
<md>
<mrow>
f(a+\De x)\approx f(a)+f'(a)(a+\De x-a)
</mrow>
</md>
and consequently the approximation
<md>
<mrow>
\De y=f(a+\De x)-f(a)\approx f(a)+f'(a)\De x-f(a)
</mrow>
</md>
simplifies to the following neat estimate of <m>\De y</m>:
</p>

<fact xml:id="eq_lineDe"><title>Linear approximation of <m>\De y</m></title>
<statement><p>
<md>
<mrow>
    \De y\approx f'(a)\De x
</mrow>
</md>
</p></statement>
</fact>
</li>
<li> In the automobile manufacturing example, when the production level is <m>a</m> cars per
week, increasing the production level by <m>\De x</m> will cost approximately
<m>f'(a)\De x</m>. The additional cost per additional car, <m>f'(a)</m>,  is called the <q>marginal
cost</q> of a car.
</li>
<li><p> If we instead use the quadratic approximation (given by
equation<nbsp/><xref ref="eq_quadApprox"/>) then we estimate
<md>
<mrow>
f(a+\De x)\approx f(a)+f'(a)\De x+\half f''(a)\De x^2
</mrow>
</md>
and so
<md>
<mrow>
\De y&amp;=f(a+\De x)-f(a) \approx f(a)+f'(a)\De x +\half f''(a)\De x^2-f(a)
</mrow>
</md>
which simplifies to</p>

<fact xml:id="eq_quadDe"><title>Quadratic approximation of <m>\De y</m></title>
<statement><p>
<md>
<mrow>
  \De y &amp;\approx f'(a)\De x+\half f''(a)\De x^2
</mrow>
</md>
</p></statement>
</fact>
</li>
</ul>
</p>
</example>
</subsection>


<subsection xml:id="ssec_taylor_more">
<title>Further Examples</title>
<p>In this subsection we give further examples of computation and use of Taylor
approximations.
</p>

<example xml:id="eg_taylorapprox"><title>Estimating <m>\tan 46^\circ</m></title>
<p>
Estimate <m>\tan 46^\circ</m>, using the constant-, linear- and quadratic-approximations
(equations<nbsp/><xref ref="eq_constApprox"/>, <xref ref="eq_linApprox"/> and<nbsp/><xref ref="eq_quadApprox"/>).
</p>

<p><alert>Solution</alert> Note that we need to be careful to translate angles measured in degrees to radians.
<ul>
<li><p> Set <m>f(x)=\tan x</m>, <m>x=46\tfrac{\pi}{180}</m> radians
and <m>a=45\tfrac{\pi}{180}=\tfrac{\pi}{4}</m> radians.
This is a good choice for <m>a</m> because
<ul>
<li>  <m>a=45^\circ</m> is close to <m>x=46^\circ</m>. As noted above, it is generally the case
that the closer <m>x</m> is to <m>a</m>, the better various approximations will be.
</li>
<li> We know the values of all trig functions at <m>45^\circ</m>.
</li>
</ul></p>
</li>
<li><p> Now we need to compute <m>f</m> and its first two derivatives at <m>x=a</m>. It is a good
time to recall the special <m>1:1:\sqrt{2}</m> triangle</p>

<sidebyside width="20%">
 <image source="text/figs/triangle45"/>
 </sidebyside>

<p>So
<md>
<mrow>
  f(x) &amp;= \tan x &amp; f(\pi/4) &amp;= 1
</mrow><mrow>
  f'(x) &amp;= \sec^2 x = \frac{1}{\cos^2 x}
  &amp; f'(\pi/4) &amp;= \frac{1}{1/\sqrt{2}^2} = 2
</mrow><mrow>
  f''(x) &amp;= \frac{2\sin x}{\cos^3 x}
  &amp; f''(\pi/4) &amp;= \frac{2/\sqrt{2}}{1/\sqrt{2}^3} = 4
</mrow>
</md></p>
</li>
<li> As <m>x-a=46\tfrac{\pi}{180}-45\tfrac{\pi}{180}=\tfrac{\pi}{180}</m> radians, the
three approximations are
<md alignment="alignat">
<mrow>
f(x)&amp;\approx f(a) 
    </mrow><mrow>
    \amp=1
</mrow><mrow>
f(x)&amp;\approx f(a)+f'(a)(x-a) &amp;
    &amp;=1+2\tfrac{\pi}{180} 
    </mrow><mrow>
    &amp;=1.034907
</mrow><mrow>
f(x)&amp;\approx f(a)+f'(a)(x\!-\!a)+\half f''(a)(x\!-\!a)^2&amp;
    &amp;=1+2\tfrac{\pi}{180}+\half 4\big(\tfrac{\pi}{180}\big)^2
    </mrow><mrow>
    &amp; =1.035516
</mrow>
</md>
For comparison purposes, <m>\tan 46^\circ</m> really is <m>1.035530</m> to 6 decimal
places.
</li>
</ul>
</p>

</example>

<warning xml:id="warning_radians">
<statement><p>
All of our derivative formulae for trig functions were developed under
the assumption that angles are measured in radians.
Those derivatives appeared in the approximation formulae that we used
in Example <xref ref="eg_taylorapprox"/>, so we were obliged to express <m>x-a</m>
in radians.
</p></statement>
</warning>


<example xml:id="eg_taylorPole"><title>Error inferring a height from an angle</title>
<p>
Suppose that you are ten meters from a vertical pole. You were
contracted to measure the height of the pole. You can't
take it down or climb it. So you measure the angle subtended by
the top of the pole. You measure <m>\theta=30^\circ</m>,  which gives
<md>
<mrow>
h=10\tan 30^\circ=\tfrac{10}{\sqrt{3}}\approx 5.77\text{m}\qquad\qquad
</mrow>
</md>
This is just standard trigonometry <mdash/>  if we know the angle exactly then we know the
height exactly.
</p>

<p>However, in the <q>real world</q> angles are hard to measure with such precision. If the
contract requires you the measurement of the pole to be accurate within <m>10</m> cm, how
accurate does your measurement of the angle <m>\theta</m> need to be?
</p>

<p><alert>Solution</alert> For simplicity
<fn>Mathematicians love assumptions that let us tame the real
world.</fn>
, we are going to assume that the pole is perfectly straight
and perfectly vertical and that your distance from the pole was exactly
10 m.
<ul>
<li> Write <m>\theta=\theta_0+\De\theta</m> where <m>\theta</m> is the exact angle, <m>\theta_0</m> is
the measured angle and <m>\De \theta</m> is the error.
</li>
<li> Similarly write <m>h=h_0+\De h</m>, where <m>h</m> is the exact height and
<m>h_0=\tfrac{10}{\sqrt{3}}</m> is the computed height. Their difference,
<m>\De h</m>, is the error.
</li>
<li> Then
<md>
<mrow>
h_0&amp;=10\tan\theta_0 &amp; h_0+\De h&amp;=10\tan(\theta_0+\De\theta)
</mrow><mrow>
\De h &amp;= 10\tan(\theta_0+\De\theta) - 10\tan\theta_0
</mrow>
</md>
We could attempt to solve this equation for <m>\De\theta</m> in terms of <m>\De h</m> <mdash/> but it is
far simpler to approximate <m>\De h</m> using the linear approximation in
equation<nbsp/><xref ref="eq_lineDe"/>.
</li>
<li> To use equation<nbsp/><xref ref="eq_lineDe"/>, replace <m>y</m> with <m>h</m>, <m>x</m> with <m>\theta</m> and <m>a</m>
with <m>\theta_0</m>. Our function <m>f(\theta) = 10 \tan\theta</m> and <m>\theta_0 = 30^\circ =
\pi/6</m> radians. Then
<md>
<mrow>
  \De y &amp;\approx f'(a) \De x &amp; \text{ becomes }&amp;&amp;
  \De h &amp;\approx f'(\theta_0) \De \theta
</mrow>
</md>
Since <m>f(\theta)=10 \tan \theta</m>, <m>f'(\theta) = 10\sec^2\theta</m> and
<md>
<mrow>
  f'(\theta_0) = 10\sec^2(\pi/6)
  = 10 \cdot \left(\frac{2}{\sqrt{3}} \right)^2 = \frac{40}{3}
</mrow>
</md>
</li>
<li> Putting things together gives
<md>
<mrow>
  \De h &amp;\approx f'(\theta_0) \De \theta &amp; \text{ becomes }&amp;&amp;
  \De h &amp; \approx \frac{40}{3} \De \theta
</mrow>
</md>
We can then solve this equation for <m>\De\theta</m> in terms of <m>\De h</m>:
<md>
<mrow>
  \De \theta &amp; \approx \frac{3}{40} \De h
</mrow>
</md>
</li>
<li> We are told that we must have <m>|\De h|  \lt  0.1</m>, so we must have
<md>
<mrow>
  |\De \theta| &amp;\leq \frac{3}{400}
</mrow>
</md>
This is measured in radians, so converting back to degrees
<md>
<mrow>
  \frac{3}{400} \cdot \frac{180}{\pi} &amp;= 0.43^\circ
</mrow>
</md>
</li>
</ul>
</p>

</example>

<definition xml:id="def_APPrelError">
<statement><p>
    Suppose that you measure, approximately, some quantity.
    Suppose that the exact value of that quantity is <m>Q_0</m>
    and that your measurement yielded <m>Q_0+\De Q</m>. Then
    <m>|\De Q|</m> is called the absolute error of the measurement
    and <m>100\frac{|\De Q|}{Q_0}</m> is called the percentage error
    of the measurement. As an example, if the exact
    value is <m>4</m> and the measured value is <m>5</m>, then the absolute
    error is <m>|5-4|=1</m> and the percentage error is
    <m>100\frac{|5-4|}{4}=25</m>. That is, the error, <m>1</m>, was <m>25\%</m>
    of the exact value, <m>4</m>.
</p></statement>
</definition>

<example xml:id="eg_taylorSphere"><title>Error inferring the area and volume from the radius</title>
<p>
Suppose that the radius of a sphere has been
measured with a percentage error of at most <m>\varepsilon</m>%. Find
the corresponding approximate percentage errors in the surface
area and volume of the sphere.
</p>

<p><alert>Solution</alert> We need to be careful in this problem to convert between absolute and percentage
errors correctly.
</p>

<p><ul>
<li> Suppose that the exact radius is <m>r_0</m> and that the measured radius is <m>r_0+\De r</m>.
</li>
<li> Then the absolute error in the measurement is <m>|\De r|</m> and, by definition, the
percentage error is <m>100\tfrac{|\De r|}{r_0}</m>. We are told that <m>100\tfrac{|\De
r|}{r_0}\le\varepsilon</m>.
</li>
<li> The surface area
<fn>We do not expect you to remember the surface areas of
solids for this course.</fn>
 of a sphere of radius <m>r</m> is <m>A(r)=4\pi r^2</m>. The error
in the surface area computed with the measured radius is
<md>
<mrow>
\De A &amp;=A(r_0+\De r)-A(r_0)\approx A'(r_0)\De r
</mrow><mrow>
&amp;= 8\pi r_0 \Delta r
</mrow>
</md>
where we have made use of the linear approximation, equation<nbsp/><xref ref="eq_lineDe"/>.
</li>
<li> The corresponding percentage error is then
<md>
<mrow>
100\frac{|\De A|}{A(r_0)}
\approx 100\frac{|A'(r_0)\De r|}{A(r_0)}
= 100\frac{8\pi r_0|\De r|}{4\pi r_0^2}
= 2\times 100\frac{|\De r|}{r_0}
\le 2\varepsilon
</mrow>
</md>
</li>
<li> The volume of a sphere
<fn>We do expect you to remember the formula for the
volume of a sphere.</fn>
 of radius <m>r</m> is <m>V(r)=\frac{4}{3}\pi r^3</m>. The error in the volume
computed with the measured radius is
<md>
<mrow>
\De V &amp;=V(r_0+\De r)-V(r_0)\approx V'(r_0)\De r
</mrow><mrow>
  &amp;= 4\pi r_0^2 \Delta r
</mrow>
</md>
where we have again made use of the linear approximation, equation<nbsp/><xref ref="eq_lineDe"/>.
</li>
<li> The corresponding percentage error is
<md>
<mrow>
100\frac{|\De V|}{V(r_0)}
\approx 100\frac{|V'(r_0)\De r|}{V(r_0)}
= 100\frac{4\pi r_0^2|\De r|}{4\pi r_0^3/3}
= 3\times 100\frac{|\De r|}{r_0}
\le 3\varepsilon
</mrow>
</md>
</li>
</ul>
We have just computed an approximation to <m>\Delta V</m>. This problem is actually
sufficiently simple that we can compute <m>\Delta V</m> exactly:
<md>
<mrow>
  \Delta V &amp;=  V(r_0 + \Delta r) - V(r_0)
	    = \tfrac{4}{3} \pi (r_0 + \Delta r)^3
	      - \tfrac{4}{3} \pi r_0^3
</mrow>
</md>
<ul>
<li> Applying <m>(a+b)^3=a^3+3a^2b+3ab^2+b^3</m> with <m>a=r_0</m> and <m>b=\De r</m>, gives
<md>
<mrow>
V(r_0+\De r)-V(r_0)&amp;=\tfrac{4}{3}\pi
\left[r_0^3+3r_0^2\De r+3r_0\,(\De r)^2+(\De r)^3\right] - \tfrac{4}{3}\pi r_0^3
</mrow><mrow>
&amp;=\tfrac{4}{3}\pi[3r_0^2\De r+3r_0\,(\De r)^2+(\De r)^3]
</mrow>
</md>
</li>
<li> Thus the difference between the exact error and the linear approximation
to the error is obtained by retaining only the last two terms in the square brackets. This
has magnitude
<md>
<mrow>
\tfrac{4}{3}\pi\big|3r_0\,(\De r)^2+(\De r)^3\big|
=\tfrac{4}{3}\pi\big|3r_0+\De r\big|(\De r)^2
</mrow>
</md>
or in percentage terms
<md>
<mrow>
100\cdot \dfrac{1}{\tfrac{4}{3}\pi r_0^3} \cdot
\tfrac{4}{3}\pi \big|3r_0\,(\De r)^2+(\De r)^3\big|

&amp;=100\left|3\frac{\De r^2}{r_0^2}+\frac{\De r^3}{r_0^3}\right|
</mrow><mrow>

&amp;=\left(100 \frac{3\De r}{r_0}\right)
\cdot \left(\frac{\De r}{r_0}\right)
\left|1 +\frac{\De r}{3r_0}\right|
</mrow><mrow>

&amp; \le 3\varepsilon \left(\frac{\varepsilon}{100}\right)\cdot \left(1+\frac{\varepsilon}{300}\right)
</mrow>
</md>
Since <m>\varepsilon</m> is small, we can assume that <m>1 + \frac{\varepsilon}{300} \approx 1</m>. Hence the
difference between the exact error and the linear approximation of the error is roughly a
factor of <m>\tfrac{\varepsilon}{100}</m> smaller than the linear approximation <m>3\varepsilon</m>.
</li>
<li> As an aside, notice that if we argue that <m>\De r</m> is very small and so we
can ignore terms involving <m>(\De r)^2</m> and <m>(\De r)^3</m> as being really really
small, then we obtain
<md>
<mrow>
V(r_0+\De r)-V(r_0)
&amp;=\tfrac{4}{3}\pi[3r_0^2\De r \underbrace{+3r_0\,(\De r)^2+(\De
r)^3}_\text{really really small}]
</mrow><mrow>
&amp;\approx \tfrac{4}{3}\pi \cdot 3r_0^2\De r  = 4 \pi r_0^2 \De r
</mrow>
</md>
which is precisely the result of our linear approximation above.
</li>
</ul>
</p></example>

<example xml:id="eg_taylorLamp"><title>Percentage error inferring a height</title>
<p>
To compute the height <m>h</m> of a lamp post, the length <m>s</m> of the
shadow of a two meter pole is measured. The pole is 6 m from the lamp post.
If the length of the shadow was measured to be 4 m, with an error of
at most one cm, find the height of the lamp post and estimate the
percentage error in the height.
</p>

<p><alert>Solution</alert> We should first draw a picture
<fn>We get to reuse that nice lamp post picture
from Example<nbsp/><xref ref="eg_fallingBall"/>.</fn>
</p>

<sidebyside width="90%">
 <image source="text/figs/lamp_shadow"/>
</sidebyside>
<p>
<ul>
<li> By similar triangles we see that
<md>
<mrow>
    \frac{2}{s} &amp;= \frac{h}{6+s}
</mrow>
</md>
from which we can isolate <m>h</m> as a function of <m>s</m>:
<md>
<mrow>
  h &amp;= \frac{2(6+s)}{s} = \frac{12}{s} + 2
</mrow>
</md>
</li>
<li> The length of the shadow was measured to be <m>s_0=4</m> m. The corresponding
height of the lamp post is
<md>
<mrow>
  h_0 &amp;= \frac{12}{4} + 2 = 5m
</mrow>
</md>
</li>
<li> If the error in the measurement of the length of the shadow was <m>\De s</m>, then the
exact shadow length was <m>s=s_0+\De s</m> and the exact lamp post height is <m>h=f(s_0+\De s)</m>,
where <m>f(s)=\tfrac{12}{s}+2</m>. The error in the computed lamp post height is
<md>
<mrow>
  \De h=h-h_0=f(s_0+\De s)-f(s_0)
</mrow>
</md>
</li>
<li> We can then make a linear approximation of this error using
equation<nbsp/><xref ref="eq_lineDe"/>:
<md>
<mrow>
\De h &amp;\approx f'(s_0)\De s =-\frac{12}{s_0^2}\De s =-\frac{12}{4^2}\De s
</mrow>
</md>
</li>
<li> We are told that <m>|\De s|\le\frac{1}{100}</m> m. Consequently, approximately,
<md>
<mrow>
 |\De h|\le \frac{12}{4^2}\frac{1}{100}=\frac{3}{400}
</mrow>
</md>
The percentage error is then approximately
<md>
<mrow>
  100\frac{|\De h|}{h_0} &amp; \le 100\frac{3}{400\times 5}=0.15\%
</mrow>
</md>
</li>
</ul>
</p></example>

</subsection>

<subsection xml:id="ssec_taylor_error">
<title>The Error in the Taylor Polynomial Approximations</title>


<p>Any time you make an approximation, it is desirable to have some idea
of the size of the error you introduced. That is, we would like to know the difference
<m>R(x)</m> between the original function <m>f(x)</m> and our approximation <m>F(x)</m>:
<md>
<mrow>
  R(x) &amp;= f(x)-F(x).
</mrow>
</md>
Of course if we know <m>R(x)</m> exactly, then we could recover <m>f(x) = F(x)+R(x)</m> <mdash/> so this
is an unrealistic hope. In practice we would simply like to bound <m>R(x)</m>:
<md>
<mrow>
  |R(x)| &amp;= |f(x)-F(x)| \leq M
</mrow>
</md>
where (hopefully) <m>M</m> is some small number. It is worth stressing that we do not need the
tightest possible value of <m>M</m>, we just need a relatively easily computed <m>M</m> that isn't
too far off the true value of <m>|f(x)-F(x)|</m>.
</p>

<p>We will now develop a formula for the error introduced by the constant approximation,
equation<nbsp/><xref ref="eq_constApprox"/> (developed back in Section<nbsp/><xref ref="ssec_const_approx"/>)
<md>
<mrow>
f(x)&amp;\approx f(a) = T_0(x) &amp; \text{$0^\mathrm{th}$ Taylor polynomial}
</mrow>
</md>
The resulting formula can be used to get an upper bound on the size of the error
<m>|R(x)|</m>.
</p>

<p>The main ingredient we will need is the Mean-Value Theorem (Theorem<nbsp/><xref ref="thm_DIFFmvt"/>)
<mdash/> so we suggest you quickly revise it. Consider the following obvious statement:
<md>
<mrow>
  f(x) &amp;= f(x) &amp; \text{now some sneaky manipulations}
</mrow><mrow>
  &amp; = f(a) + (f(x)-f(a))
</mrow><mrow>
  &amp;= \underbrace{f(a)}_{=T_0(x)} + (f(x)-f(a)) \cdot \underbrace{\frac{x-a}{x-a}}_{=1}
</mrow><mrow>
  &amp;= T_0(x) + \underbrace{\frac{f(x)-f(a)}{x-a}}_\text{looks familiar} \cdot (x-a)
</mrow>
</md>
Indeed, this equation is important in the discussion that follows, so we'll highlight it</p>

<fact xml:id="eq_taylorErrorA"><title>We will need it again soon</title>
<statement><p>
 <md>
<mrow>
  f(x) &amp;= T_0(x) + \left[ \frac{f(x)-f(a)}{x-a} \right](x-a)
 </mrow>
</md>
</p></statement>
</fact>

<p>The coefficient <m>\dfrac{f(x)-f(a)}{x-a}</m> of <m>(x-a)</m> is the average slope
of <m>f(t)</m> as <m>t</m> moves from <m>t=a</m> to <m>t=x</m>. We can picture this as the slope of the secant joining the points <m>(a,f(a))</m> and <m>(x,f(x))</m> in the sketch below.</p>

<sidebyside width="50%">
<image source="text/figs/approx4bb"/>
</sidebyside>

<p>As <m>t</m> moves from <m>a</m> to <m>x</m>, the instantaneous slope <m>f'(t)</m> keeps changing. Sometimes
<m>f'(t)</m> might be larger than the average slope <m>\tfrac{f(x)-f(a)}{x-a}</m>, and sometimes
<m>f'(t)</m> might be smaller than the average slope <m>\tfrac{f(x)-f(a)}{x-a}</m>. However, by the
Mean-Value Theorem (Theorem<nbsp/><xref ref="thm_DIFFmvt"/>), there must be some number <m>c</m>, strictly between <m>a</m> and <m>x</m>, for which  <m>f'(c)=\dfrac{f(x)-f(a)}{x-a}</m> exactly.
</p>

<p>Substituting this into formula <xref ref="eq_taylorErrorA"/> gives</p>

<fact xml:id="eq_taylorErrorL"><title>Towards the error</title>
<statement><p>
<md>
<mrow>
  f(x) &amp;=T_0(x) +f'(c)(x-a) &amp; \text{for some $c$ strictly between $a$ and $x$}
</mrow>
</md>
</p></statement>
</fact>

<p>Notice that this expression as it stands is not quite what we want. Let us massage this
around a little more into a more useful form</p>

<fact xml:id="eq_taylorErrorL2"><title>The error in constant approximation</title>
<statement><p>
 <md>
<mrow>
  f(x) - T_0(x) &amp;= f'(c) \cdot (x-a) &amp; \text{for some $c$ strictly between
$a$ and $x$}
</mrow>
</md>
</p></statement>
</fact>

<p>Notice that the MVT doesn't tell us the value of <m>c</m>, however we do know that it lies
strictly between <m>x</m> and <m>a</m>. So if we can get a good bound on <m>f'(c)</m> on this interval then we can get a good bound on the error.
</p>

<example xml:id="eg_zero_approx_of_e"><title>Error in the approximation in <xref ref="eg_ex_const_approx"/></title>
<p>
  Let us return to Example<nbsp/><xref ref="eg_ex_const_approx"/>, and we'll try to bound the error in
our approximation of<nbsp/><m>e^{0.1}</m>.
</p>

<p><ul>
<li> Recall that <m>f(x) = e^x</m>, <m>a=0</m> and <m>T_0(x) = e^0 = 1</m>.
</li>
<li> Then by equation<nbsp/><xref ref="eq_taylorErrorL2"/>
  <md>
<mrow>
    e^{0.1} - T_0(0.1) &amp;= f'(c) \cdot (0.1 - 0) &amp; \text{with $0 \lt c \lt 0.1$}
  </mrow>
</md>
</li>
<li> Now <m>f'(c) = e^c</m>, so we need to bound <m>e^c</m> on <m>(0,0.1)</m>. Since <m>e^c</m> is an
  increasing function, we know that
  <md>
<mrow>
    e^0 &amp; \lt  f'(c)  \lt  e^{0.1}  &amp; \text{ when $0 \lt c \lt 0.1$}
  </mrow>
</md>
  So one is tempted to write that
  <md>
<mrow>
    |e^{0.1} - T_0(0.1)| &amp;= |R(x)| = |f'(c)| \cdot (0.1 - 0)
</mrow><mrow>
    &amp;  \lt  e^{0.1} \cdot 0.1
  </mrow>
</md>
  And while this is true, it is rather circular. We have just bounded the error in our
  approximation of <m>e^{0.1}</m> by <m>\frac{1}{10}e^{0.1}</m> <mdash/> if we actually knew <m>e^{0.1}</m>
  then we wouldn't need to estimate it!
</li>
<li> While we don't know <m>e^{0.1}</m> exactly, we do know
<fn>Oops! Do we really know that <m>e \lt 3</m>? We haven't proved it. We will do so soon.</fn>
that <m>1 = e^0  \lt  e^{0.1}  \lt  e^1  \lt
3</m>. This   gives us
  <md>
<mrow>
    |R(0.1)|  \lt  3 \times 0.1 = 0.3
  </mrow>
</md>
  That is <mdash/> the error in our approximation of <m>e^{0.1}</m> is no greater than <m>0.3</m>.
  Recall that we don't need the error exactly, we just need a good idea of how large it
  actually is.
</li>
<li> In fact the real error here is
<md>
<mrow>
  |e^{0.1} - T_0(0.1)| &amp;=|e^{0.1} - 1| = 0.1051709\dots
</mrow>
</md>
so we have over-estimated the error by a factor of 3.
</li>
</ul>
</p>

<p>But we can actually go a little further here <mdash/> we can bound the error above and below.
If we do not take absolute values, then since
  <md>
<mrow>
    e^{0.1} - T_0(0.1) &amp;= f'(c) \cdot 0.1 &amp; \text{ and } 1  \lt  f'(c)  \lt  3
  </mrow>
</md>
we can write
<md>
<mrow>
  1\times 0.1 \leq ( e^{0.1} - T_0(0.1) ) &amp; \leq 3\times 0.1
</mrow>
</md>
so
<md>
<mrow>
  T_0(0.1) + 0.1 &amp;\leq e^{0.1} \leq T_0(0.1)+0.3
</mrow><mrow>
  1.1 &amp;\leq e^{0.1} \leq 1.3
</mrow>
</md>
So while the upper bound is weak, the lower bound is quite tight.
</p>

</example>

<p>There are formulae similar to equation<nbsp/><xref ref="eq_taylorErrorL"/>, that can be used to bound
the error in our other approximations; all are based on generalisations of the
MVT. The next one <mdash/> for linear approximations <mdash/> is
<md>
<mrow>
f(x) &amp; =\underbrace{f(a)+f'(a)(x-a)}_{=T_1(x)}+\half f''(c)(x-a)^2 &amp;
\text{for some } c \text{ strictly between } a \text{ and } x
</mrow>
</md>
which we can rewrite in terms of <m>T_1(x)</m>:</p>

<fact xml:id="eq_taylorErrorQ"><title>The error in linear approximation</title>
<statement><p>
<md>
<mrow>
f(x)-T_1(x) &amp;=  \half f''(c)(x-a)^2 &amp;
\text{for some } c \text{ strictly between } a \text{ and } x
</mrow>
</md>
</p></statement>
</fact>

<p> It implies that the error that we make when we approximate <m>f(x)</m> by
<m>T_1(x) = f(a)+f'(a)\,(x-a)</m> is exactly <m>\half f''(c)\,(x-a)^2</m> for some <m>c</m> strictly
between <m>a</m> and <m>x</m>.
</p>

<p>More generally
<md>
<mrow>
f(x)=&amp;
\underbrace{f(a)\!+\!f'(a)\cdot(x\!-\!a)\!+\cdots+\!\frac{1}{n!}f^{(n)}(a)\cdot(x\!-\!a)^n}_{= T_n(x)}
\!+\!\frac{1}{(n\!+\!1)!}f^{(n+1)}(c)\cdot (x\!-\!a)^{n+1}
</mrow>
</md>
for some <m>c</m> strictly between <m>a</m> and <m>x</m>. Again, rewriting this in terms of <m>T_n(x)</m>
gives</p>

<fact xml:id="eq_taylorErrorN">
<statement><p>
<md>
<mrow>
  f(x) - T_n(x) &amp;= \frac{1}{(n+1)!}f^{(n+1)}(c)\cdot (x-a)^{n+1}
\quad \text{for some $c$ strictly between $a$ and $x$}
</mrow>
</md>
</p></statement>
</fact>

<p>That is, the error introduced when <m>f(x)</m> is approximated by its Taylor
polynomial of degree <m>n</m>, is precisely the last term of the Taylor polynomial
of degree <m>n+1</m>, but with the derivative evaluated at some point between
<m>a</m> and <m>x</m>, rather than exactly at <m>a</m>. These error formulae are proven
in the optional Section<nbsp/><xref ref="subsec_GMVT"/> later in this chapter.
</p>

<example xml:id="eg_taylorErrorSin"><title>Approximate <m>\sin 46^\circ</m> and estimate the error</title>
<p>
Approximate <m>\sin 46^\circ</m> using Taylor polynomials about
<m>a=45^\circ</m>, and estimate the resulting error.
</p>

<p><alert>Solution</alert>
<ul>
<li> Start by defining <m>f(x) = \sin x</m> and
<md>
<mrow>
a&amp;=45^\circ=45\tfrac{\pi}{180} {\rm radians}&amp;
x&amp;=46^\circ=46\tfrac{\pi}{180} {\rm radians}
</mrow><mrow>
x-a&amp;=\tfrac{\pi}{180} {\rm radians}
</mrow>
</md>
</li>
<li> The first few derivatives of <m>f</m> at <m>a</m> are
<md>
<mrow>
f(x)&amp;=\sin x
&amp;f(a)&amp;=\frac{1}{\sqrt{2}}
</mrow><mrow>
f'(x)&amp;=\cos x &amp;
</mrow><mrow>
f'(a)&amp;=\frac{1}{\sqrt{2}}
</mrow><mrow>
f''(x)&amp;=-\sin x &amp;
</mrow><mrow>
f''(a)&amp;=-\frac{1}{\sqrt{2}}
</mrow><mrow>
f^{(3)}(x)&amp;=-\cos x &amp;
f^{(3)}(a)&amp;=-\frac{1}{\sqrt{2}}
</mrow>
</md>
</li>
<li>
The constant, linear and quadratic Taylor approximations for <m>\sin(x)</m> about
<m>\frac{\pi}{4}</m> are
<md alignment="alignat">
<mrow>
  T_0(x) &amp;= f(a)
    &amp;&amp;= \frac{1}{\sqrt{2}}
</mrow><mrow>
  T_1(x) &amp;= T_0(x) + f'(a) \cdot(x\!-\!a)
    &amp;&amp;= \frac{1}{\sqrt{2}} + \frac{1}{\sqrt{2}}\left(x\! -\! \frac{\pi}{4} \right)
</mrow><mrow>
  T_2(x) &amp;= T_1(x)\! +\! \half f''(a) \cdot(x\!-\!a)^2
    &amp;&amp;=\!  \frac{1}{\sqrt{2}} \!+\! \frac{1}{\sqrt{2}}\left(x\!-\! \frac{\pi}{4} \right)
  \!-\! \frac{1}{2\sqrt{2}}\left(x\! -\! \frac{\pi}{4} \right)^2
</mrow>
</md>
</li>
<li> So the approximations for <m>\sin 46^\circ</m> are
<md>
<mrow>
\sin46^\circ &amp;\approx T_0\left(\frac{46\pi}{180}\right) = \frac{1}{\sqrt{2}}
</mrow><mrow> 
&amp;=0.70710678
</mrow><mrow>
\sin46^\circ &amp;\approx T_1\left(\frac{46\pi}{180}\right)
= \frac{1}{\sqrt{2}} + \frac{1}{\sqrt{2}} \left(\frac{\pi}{180}\right)
</mrow><mrow>
&amp;=0.71944812
</mrow><mrow>
\sin46^\circ&amp;\approx T_2\left(\frac{46\pi}{180}\right)
= \frac{1}{\sqrt{2}} + \frac{1}{\sqrt{2}} \left(\frac{\pi}{180}\right)
- \frac{1}{2\sqrt{2}}\left(\frac{\pi}{180}\right)^2
</mrow><mrow>
 &amp;=0.71934042
</mrow>
</md>
</li>
<li> The errors in those approximations are (respectively)
<md alignment="alignat">
<mrow>
&amp;{\rm error\ in\ 0.70710678}&amp;
     &amp;=f'(c)(x-a)&amp;
     &amp;=\cos c \cdot \left(\frac{\pi}{180}\right)
</mrow><mrow>
     &amp;{\rm error\ in\ 0.71944812}&amp;
   &amp;=\frac{1}{2} f''(c)(x-a)^2&amp;
   &amp;=-\frac{1}{2} \cdot \sin c\cdot \left(\frac{\pi}{180}\right)^2
</mrow><mrow>
&amp;{\rm error\ in\ 0.71923272}&amp;
   &amp;=\frac{1}{3!}f^{(3)}(c)(x-a)^3&amp;
   &amp;=-\frac{1}{3!}\cdot \cos c \cdot \left(\frac{\pi}{180}\right)^3
</mrow>
</md>
In each of these three cases <m>c</m> must lie somewhere between <m>45^\circ</m> and
<m>46^\circ</m>.
</li>
<li> Rather than carefully estimating <m>\sin c</m> and <m>\cos c</m> for <m>c</m> in that range, we
make use of a simpler (but much easier bound). No matter what <m>c</m> is, we know that <m>|\sin
c|\le 1</m> and <m>|\cos c|\le 1</m>. Hence
<md alignment="alignat">
<mrow>
&amp;\big|{\rm error\ in\ 0.70710678}\big|&amp;
   &amp;\le  \left(\frac{\pi}{180}\right)&amp;
   &amp; \lt 0.018
</mrow><mrow>
&amp;\big|{\rm error\ in\ 0.71944812}\big|&amp;
   &amp;\le\frac{1}{2} \left(\frac{\pi}{180}\right)^2&amp;
   &amp; \lt 0.00015
</mrow><mrow>
&amp;\big|{\rm error\ in\ 0.71934042}\big|&amp;
   &amp;\le \frac{1}{3!} \left(\frac{\pi}{180}\right)^3&amp;
  &amp; \lt 0.0000009
</mrow>
</md>
</li>
</ul>
</p>

</example>

<example><title>Showing <m>e \lt 3</m></title>
<p>
In Example<nbsp/><xref ref="eg_zero_approx_of_e"/> above we used the fact that <m>e \lt 3</m> without actually
proving it. Let's do so now.
</p>

<p><ul>
<li> Consider the linear approximation of <m>e^x</m> about <m>a=0</m>.
<md>
<mrow>
  T_1(x) &amp;= f(0) + f'(0)\cdot x = 1 + x
</mrow>
</md>
So at <m>x=1</m> we have
<md>
<mrow>
  e &amp;\approx T_1(1) = 2
</mrow>
</md>
</li>
<li> The error in this approximation is
<md>
<mrow>
  e^x - T_1(x) &amp;= \frac{1}{2} f''(c) \cdot x^2 = \frac{e^c}{2} \cdot x^2
</mrow>
</md>
So at <m>x=1</m> we have
<md>
<mrow>
  e - T_1(1) &amp;= \frac{e^c}{2}
</mrow>
</md>
where <m>0 \lt c \lt 1</m>.
</li>
<li> Now since <m>e^x</m> is an increasing
<fn>Since the derivative of <m>e^x</m> is <m>e^x</m>
which is positive everywhere, the function is increasing everywhere.</fn>
 function, it
follows that <m>e^c  \lt  e</m>. Hence
<md>
<mrow>
  e - T_1(1) &amp;= \frac{e^c}{2}  \lt  \frac{e}{2}
</mrow>
</md>
Moving the <m>\frac{e}{2}</m> to the left hand side and the <m>T_1(1)</m> to the right
hand side gives
<md>
<mrow>
  \frac{e}{2} \leq T_1(1) = 2
</mrow>
</md>
So <m>e \lt 4</m>.
</li>
<li> This isn't as tight as we would like <mdash/> so now do the same with the
quadratic approximation with <m>a=0</m>:
<md>
<mrow>
  e^x &amp; \approx T_2(x) = 1 + x + \frac{x^2}{2}
</mrow>
<intertext>So when <m>x=1</m> we have</intertext><mrow>
  e &amp; \approx T_2(1) = 1 + 1 + \frac{1}{2} = \frac{5}{2}
</mrow>
</md>
</li>
<li> The error in this approximation is
<md>
<mrow>
  e^x - T_2(x) &amp;= \frac{1}{3!} f'''(c) \cdot x^3 = \frac{e^c}{6} \cdot x^3
</mrow>
</md>
So at <m>x=1</m> we have
<md>
<mrow>
  e - T_2(1) &amp;= \frac{e^c}{6}
</mrow>
</md>
where <m>0 \lt c \lt 1</m>.
</li>
<li> Again since <m>e^x</m> is an increasing function we have <m>e^c  \lt  e</m>. Hence
<md>
<mrow>
  e - T_2(1) &amp;= \frac{e^c}{6}  \lt  \frac{e}{6}
</mrow>
</md>
That is
<md>
<mrow>
  \frac{5e}{6} \lt T_2(1) = \frac{5}{2}
</mrow>
</md>
So <m>e \lt 3</m> as required.
</li>
</ul>
</p>

</example>

<example xml:id="eg_exp"><title>More on <m>e^x</m></title>
<p>
We wrote down the general <m>n^\mathrm{th}</m> degree Maclaurin polynomial approximation of
<m>e^x</m> in Example<nbsp/><xref ref="eg_taylor_e_to_the_x"/> above.
<ul>
<li> Recall that
<md>
<mrow>
  T_n(x) &amp;= \sum_{k=0}^n \frac{1}{k!} x^k
</mrow>
</md>
</li>
<li> The error in this approximation is (by equation<nbsp/><xref ref="eq_taylorErrorN"/>)
<md>
<mrow>
  e^x - T_n(x) &amp;= \frac{1}{(n+1)!} e^c
</mrow>
</md>
where <m>c</m> is some number between <m>0</m> and <m>x</m>.
</li>
<li> So setting <m>x=1</m> in this gives
<md>
<mrow>
  e - T_n(1) &amp;= \frac{1}{(n+1)!} e^c
</mrow>
</md>
where <m>0 \lt c \lt 1</m>.
</li>
<li> Since <m>e^x</m> is an increasing function we know that <m>1 = e^0  \lt  e^c  \lt  e^1  \lt  3</m>, so
the above expression becomes
<md>
<mrow>
  \frac{1}{(n+1)!} \leq e - T_n(1) &amp;= \frac{1}{(n+1)!} e^c \leq \frac{3}{(n+1)!}
</mrow>
</md>
</li>
<li> So when <m>n=9</m> we have
<md>
<mrow>
  \frac{1}{10!} \leq e - \left(1 + 1 + \frac{1}{2} +\cdots + \frac{1}{9!} \right) &amp;\leq
  \frac{3}{10!}
</mrow>
</md>
</li>
<li> Now <m>1/10!  \lt  3/10!  \lt  10^{-6}</m>, so the approximation of <m>e</m> by
<md>
<mrow>
  e \approx 1 + 1 + \frac{1}{2} +\cdots + \frac{1}{9!} = \frac{98641}{36288} =
2.718281\dots
</mrow>
</md>
is correct to 6 decimal places.
</li>
<li> More generally we know that using <m>T_n(1)</m> to approximate <m>e</m> will have an error of
at most <m>\frac{3}{(n+1)!}</m> <mdash/> so it converges very quickly.
</li>
</ul>
</p>
</example>

<example><title><xref ref="eg_taylorPole" text="type-global" /> Revisited</title>
<p>
Recall
<fn>Now is a good time to go back and re-read it.</fn>
 that in Example
<xref ref="eg_taylorPole"/> (measuring the height of the pole), we
used the linear approximation
<md>
<mrow>
f(\theta_0+\De\theta)&amp;\approx f(\theta_0)+f'(\theta_0)\De\theta
</mrow>
</md>
with <m>f(\theta)=10\tan\theta</m> and <m>\theta_0=30\dfrac{\pi}{180}</m> to get
<md>
<mrow>
\De h &amp;=f(\theta_0+\De\theta)-f(\theta_0)\approx f'(\theta_0)\De\theta
  \quad \text{which implies that} \quad
  \De\theta \approx \frac{\De h}{f'(\theta_0)}
</mrow>
</md>
<ul>
<li> While this procedure is fairly reliable, it did involve an approximation.
So that you could not 100% guarantee to your client's lawyer  that an accuracy of 10 cm
was achieved.
</li>
<li> On the other hand, if we use the <em>exact</em> formula <xref ref="eq_taylorErrorL"/>, with
the replacements
<m>x\rightarrow \theta_0+\De\theta</m> and <m>a\rightarrow\theta_0</m>
<md>
<mrow>
f(\theta_0+\De\theta)&amp;=f(\theta_0)+f'(c)\De\theta
&amp; \text{for some $c$ between $\theta_0$ and $\theta_0+\De\theta$}
</mrow>
</md>
in place of the approximate formula <xref ref="eq_linApprox"/>, this legality
is taken care of:
<md>
<mrow>
\De h &amp;=f(\theta_0\!+\!\De\theta)-f(\theta_0) =f'(c)\De\theta
\quad \text{for some $c$ between $\theta_0$ and $\theta_0+\De\theta$}
</mrow>
</md>
We can clean this up a little more since in our example <m>f'(\theta) = 10\sec^2\theta</m>.
Thus for some <m>c</m> between <m>\theta_0</m> and <m>\theta_0 + \De\theta</m>:
<md>
<mrow>
|\De h| = 10 \sec^2(c) |\De \theta|
</mrow>
</md>
</li>
<li> Of course we do not know exactly what <m>c</m> is. But suppose that we know
that the angle was somewhere between <m>25^\circ</m> and <m>35^\circ</m>. In other
words suppose that, even though we don't know precisely
what our measurement error was, it was certainly no more than <m>5^\circ</m>.
</li>
<li> Now on the range <m>25^\circ  \lt  c  \lt  35^\circ</m>, <m>\sec(c)</m> is an increasing and
positive function. Hence on this range
<md>
<mrow>
  1.217\dots  = \sec^2 25^\circ \leq \sec^2 c \leq \sec^2 35^\circ = 1.490\dots
 \lt  1.491
</mrow>
</md>
So
<md>
<mrow>
  12.17 \cdot |\De \theta| &amp;\leq |\De h|
  = 10 \sec^2(c) \cdot |\De \theta| \leq 14.91 \cdot
  | \De \theta|
</mrow>
</md>
</li>
<li> Since we require <m>|\De h|  \lt  0.1</m>, we need <m>14.91 |\De \theta|  \lt 0.1</m>, that
is
<md>
<mrow>
|\De \theta|  \lt  \frac{0.1}{14.91} = 0.0067\dots
</mrow>
</md>
So we must measure angles with an accuracy of no less than <m>0.0067</m> radians <mdash/>
which is
<md>
<mrow>
  \frac{180}{\pi} \cdot 0.0067 = 0.38^\circ.
</mrow>
</md>
Hence a measurement error of <m>0.38^\circ</m> or less is acceptable.
</li>
</ul>
</p>
</example>

</subsection>

<subsection xml:id="subsec_GMVT" >
<title>(Optional) <mdash/> Derivation of the Error Formulae</title>

<p>In this section we will derive the formula for the error that we gave in
equation<nbsp/><xref ref="eq_taylorErrorN"/> <mdash/> namely
<md>
<mrow>
  R_n(x) = f(x) - T_n(x) &amp;= \frac{1}{(n+1)!}f^{(n+1)}(c)\cdot (x-a)^{n+1}
</mrow>
</md>
for some <m>c</m> strictly between <m>a</m> and <m>x</m>, and where <m>T_n(x)</m> is the <m>n^\mathrm{th}</m>
degree Taylor polynomial approximation of <m>f(x)</m> about <m>x=a</m>:
<md>
<mrow>
  T_n(x) &amp;= \sum_{k=0}^n \frac{1}{k!} f^{(k)}(a).
</mrow>
</md>
Recall that we have already proved a special case of this formula for the constant
approximation using the Mean-Value Theorem (Theorem<nbsp/><xref ref="thm_DIFFmvt"/>). To prove the
general case we need the following generalisation
<fn>It is not a terribly creative name for the generalisation, but it is an accurate one.</fn>
 of that theorem:</p>

<theorem xml:id="thm_GMVT"><title>Generalised Mean-Value Theorem</title>
<statement><p>
Let the functions <m>F(x)</m> and <m>G(x)</m> both be defined and continuous on
<m>a\le x\le b</m> and both be differentiable on <m>a \lt x \lt b</m>. Furthermore, suppose
that <m>G'(x)\ne 0</m> for all <m>a \lt x \lt b</m>.
Then, there is a number <m>c</m> obeying <m>a \lt c \lt b</m> such that
<md>
<mrow>
\frac{F(b)-F(a)}{G(b)-G(a)}=\frac{F'(c)}{G'(c)}
</mrow>
</md>
</p></statement>
</theorem>

<p>Notice that setting <m>G(x) = x</m> recovers the original Mean-Value Theorem. It turns out
that this theorem is not too difficult to prove from the MVT using some sneaky algebraic
manipulations:</p>

<proof>
<p>
<ul>
<li> First we construct a new function <m>h(x)</m> as a linear combination of <m>F(x)</m> and
  <m>G(x)</m> so that <m>h(a)=h(b)=0</m>. Some experimentation yields
  <md>
<mrow>
  h(x)=\big[F(b)-F(a)\big]\cdot \big[G(x)-G(a)\big]-
  \big[G(b)-G(a)\big] \cdot \big[F(x)-F(a)\big]
  </mrow>
</md>
</li>
<li> Since <m>h(a)=h(b)=0</m>, the Mean-Value theorem (actually Rolle's theorem) tells us
that there is a number <m>c</m> obeying <m>a \lt c \lt b</m> such that <m>h'(c)=0</m>:
<md>
<mrow>
  h'(x) &amp;= \big[F(b)-F(a)\big] \cdot G'(x) - \big[G(b)-G(a)\big] \cdot F'(x) &amp; \text{
so}
</mrow><mrow>
  0 &amp;= \big[F(b)-F(a)\big] \cdot G'(c) - \big[G(b)-G(a)\big] \cdot F'(c)
</mrow>
</md>
Now move the <m>G'(c)</m> terms to one side and the <m>F'(c)</m> terms to the other:
<md>
<mrow>
  \big[F(b)-F(a)\big] \cdot G'(c) &amp;= \big[G(b)-G(a)\big] \cdot F'(c).
</mrow>
</md>
</li>
<li> Since we have <m>G'(x) \neq 0</m>, we know that <m>G'(c) \neq 0</m>. Further the Mean-Value
theorem ensures
<fn>Otherwise if <m>G(a)=G(b)</m> the MVT tells us that there is some
point <m>c</m> between <m>a</m> and <m>b</m> so that <m>G'(c)=0</m>.</fn>
 that <m>G(a) \neq G(b)</m>. Hence we can
move terms about to get
<md>
<mrow>
  \big[F(b)-F(a)\big] &amp;= \big[G(b)-G(a)\big] \cdot \frac{F'(c)}{G'(c)}
</mrow><mrow>
  \frac{F(b)-F(a)}{G(b)-G(a)} &amp;=  \frac{F'(c)}{G'(c)}
</mrow>
</md>
as required.
</li>
</ul>
</p>

</proof>

<p>Armed with the above theorem we can now move on to the proof of the Taylor remainder
formula.
</p>

<proof><title>Proof of equation<nbsp/><xref ref="eq_taylorErrorN"/></title>
<p>
We begin by proving the remainder formula for <m>n=1</m>. That is
<md>
<mrow>
  f(x) - T_1(x) &amp;= \frac{1}{2}f''(c) \cdot(x-a)^2
</mrow>
</md>
<ul>
<li> Start by setting
<md>
<mrow>
  F(x) &amp;= f(x)-T_1(x) &amp;
  G(x) &amp;= (x-a)^2
</mrow>
</md>
Notice that, since <m>T_1(a)=f(a)</m> and <m>T'_1(x) = f'(a)</m>,
<md>
<mrow>
  F(a) &amp;= 0 &amp; G(a)&amp;=0
</mrow><mrow>
  F'(x) &amp;= f'(x)-f'(a) &amp; G'(x) &amp;= 2(x-a)
</mrow>
</md>
</li>
<li> Now apply the generalised MVT with <m>b=x</m>: there exists a point <m>q</m> between <m>a</m> and
<m>x</m> such that
<md>
<mrow>
  \frac{F(x)-F(a)}{G(x)-G(a)} &amp;= \frac{F'(q)}{G'(q)}
</mrow><mrow>
  \frac{F(x)-0}{G(x) - 0} &amp;= \frac{f'(q)-f'(a)}{2(q-a)}
</mrow><mrow>
  2 \cdot \frac{F(x)}{G(x)} &amp;= \frac{f'(q)-f'(a)}{q-a}
</mrow>
</md>
</li>
<li> Consider the right-hand side of the above equation and set <m>g(x) = f'(x)</m>. Then we
have the term <m>\frac{g(q)-g(a)}{q-a}</m>  <mdash/> this is exactly the form needed to apply the
MVT. So now apply the standard MVT to the right-hand side of the above equation
<mdash/> there is some <m>c</m> between <m>q</m> and <m>a</m> so that
<md>
<mrow>
  \frac{f'(q)-f'(a)}{q-a} &amp;= \frac{g(q)-g(a)}{q-a} = g'(c) = f''(c)
</mrow>
</md>
Notice that here we have assumed that <m>f''(x)</m> exists.
</li>
<li> Putting this together we have that
<md>
<mrow>
  2 \cdot \frac{F(x)}{G(x)} &amp;= \frac{f'(q)-f'(a)}{q-a} = f''(c)
</mrow><mrow>
  2 \frac{f(x)-T_1(x)}{(x-a)^2} &amp;= f''(c)
</mrow><mrow>
  f(x) - T_1(x) &amp;= \frac{1}{2!} f''(c) \cdot (x-a)^2
</mrow>
</md>
as required.
</li>
</ul>
Oof! We have now proved the cases <m>n=1</m> (and we did <m>n=0</m> earlier).
</p>

<p>To proceed <mdash/> assume we have proved our result for <m>n=1,2,\cdots, k</m>. We realise
that we haven't done this yet, but bear with us. Using that assumption we will
prove the result is true for <m>n=k+1</m>. Once we have done that, then
<ul>
<li> we have proved the result is true for <m>n=1</m>, and
</li>
<li> we have shown if the result is true for <m>n=k</m> then it is true for <m>n=k+1</m>
</li>
</ul>
Hence it must be true for all <m>n \geq 1</m>. This style of proof is called
mathematical induction. You can think of the process as something like climbing
a ladder:
<ul>
<li> prove that you can get onto the ladder (the result is true for <m>n=1</m>),
and
</li>
<li> if I can stand on the current rung, then I can step up to the next rung (if the
result is true for <m>n=k</m> then it is also true for <m>n=k+1</m>)
</li>
</ul>
Hence I can climb as high as like.
</p>

<p><ul>
<li> Let <m>k \gt 0</m> and assume we have proved
<md>
<mrow>
  f(x) - T_k(x) &amp;= \frac{1}{(k+1)!} f^{(k+1)}(c) \cdot (x-a)^{k+1}
</mrow>
</md>
for some <m>c</m> between <m>a</m> and <m>x</m>.
</li>
<li> Now set
<md>
<mrow>
  F(x) &amp;= f(x) - T_{k+1}(x) &amp; G(x) &amp;= (x-a)^{k+1}
</mrow>
<intertext>and notice that, since <m>T_{k+1}(a)=f(a)</m>,</intertext>
<mrow>
  F(a) &amp;= f(a)-T_{k+1}(a)=0 &amp; G(a) &amp;= 0 &amp; G'(x) &amp;= (k+1)(x-a)^k
</mrow>
</md>
and apply the generalised MVT with <m>b=x</m>: hence there exists a <m>q</m> between <m>a</m> and <m>x</m> so
that
<md>
<mrow>
  \frac{F(x)-F(a)}{G(x)-G(a)} &amp;= \frac{F'(q)}{G'(q)} &amp;\text{which becomes}
</mrow><mrow>
  \frac{F(x)}{(x-a)^{k+1}} &amp;= \frac{F'(q)}{(k+1)(q-a)^k} &amp; \text{rearrange}
</mrow><mrow>
  F(x) &amp;= \frac{(x-a)^{k+1}}{(k+1)(q-a)^k} \cdot F'(q)
</mrow>
</md>
</li>
<li> We now examine <m>F'(q)</m>. First carefully differentiate <m>F(x)</m>:
<md>
<mrow>
  F'(x) &amp;= \diff{}{x} \bigg[f(x) - \bigg( f(a) + f'(a)(x-a) + \frac{1}{2}
f''(a)(x-a)^2 + \cdots 
  </mrow><mrow>\amp\hskip2.5in+ \frac{1}{k!}f^{(k)}(x-a)^k \bigg)  \bigg]
</mrow><mrow>
  &amp;= f'(x) - \bigg( f'(a) + \frac{2}{2} f''(a)(x-a) + \frac{3}{3!} f'''(a)(x-a)^2 +
\cdots 
  </mrow><mrow>\amp\hskip2.5in+ \frac{k}{k!}f^{(k)}(a) (x-a)^{k-1} \bigg)
</mrow><mrow>
  &amp;= f'(x) - \bigg( f'(a) + f''(a)(x-a) + \frac{1}{2} f'''(a)(x-a)^2 +\cdots 
  </mrow><mrow>\amp\hskip2.5in+ \frac{1}{(k-1)!}f^{(k)}(a)(x-a)^{k-1} \bigg)
</mrow>
</md>
Now notice that if we set <m>f'(x) = g(x)</m> then this becomes
<md>
<mrow>
F'(x) &amp;= g(x) - \bigg( g(a) + g'(a)(x-a) + \frac{1}{2} g''(a)(x-a)^2 +
\cdots 
</mrow><mrow>\amp\hskip2.5in+ \frac{1}{(k-1)!}g^{(k-1)}(a)(x-a)^{k-1} \bigg)
</mrow>
</md>
So <m>F'(x)</m> is then exactly the remainder formula but for a degree <m>k-1</m> approximation
to the function <m>g(x) = f'(x)</m>.
</li>
<li> Hence the function <m>F'(q)</m> is the remainder when we approximate <m>f'(q)</m> with a
degree <m>k-1</m> Taylor polynomial. The remainder formula, equation<nbsp/><xref ref="eq_taylorErrorN"/>,
then tells us that there is a number <m>c</m> between <m>a</m> and <m>q</m> so that
<md>
<mrow>
  F'(q) &amp;= g(q) - \bigg( g(a) + g'(a)(q-a) + \frac{1}{2} g''(a)(q-a)^2 + \cdots 
 </mrow><mrow>\amp\hskip2.5in + \frac{1}{(k-1)!}g^{(k-1)}(a)(q-a)^{k-1} \bigg)
</mrow><mrow>
  &amp;= \frac{1}{k!} g^{(k)}(c) (q-a)^k = \frac{1}{k!} f^{(k+1)}(c)(q-a)^k
</mrow>
</md>
Notice that here we have assumed that <m>f^{(k+1)}(x)</m> exists.
</li>
<li> Now substitute this back into our equation above
<md>
<mrow>
  F(x) &amp;= \frac{(x-a)^{k+1}}{(k+1)(q-a)^k} \cdot F'(q)
</mrow><mrow>
  &amp;= \frac{(x-a)^{k+1}}{(k+1)(q-a)^k} \cdot \frac{1}{k!} f^{(k+1)}(c)(q-a)^k
</mrow><mrow>
  &amp;= \frac{1}{(k+1)k!} \cdot f^{(k+1)}(c) \cdot
\frac{(x-a)^{k+1}(q-a)^k}{(q-a)^k}
</mrow><mrow>
  &amp;= \frac{1}{(k+1)!} \cdot f^{(k+1)}(c) \cdot(x-a)^{k+1}
</mrow>
</md>
as required.
</li>
</ul>
</p>

<p>So we now know that
<ul>
<li> if, for some <m>k</m>, the remainder formula (with <m>n=k</m>) is true
for all <m>k</m> times differentiable functions,
</li>
<li> then the remainder formula  is true (with <m>n=k+1</m>) for all <m>k+1</m> times
differentiable functions.
</li>
</ul>
Repeatedly applying this for <m>k=1,2,3,4,\cdots</m> (and recalling that we have shown the
remainder formula is true when <m>n=0,1</m>)  gives  equation<nbsp/><xref ref="eq_taylorErrorN"/> for all
<m>n=0,1,2,\cdots</m>.
</p></proof>

</subsection>

<xi:include href="../problems/prob_s3.4.xml" />

</section>
